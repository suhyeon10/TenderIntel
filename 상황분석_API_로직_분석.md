# ìƒí™©ë¶„ì„ API ë¡œì§ ë¶„ì„ ë° ì ˆì°¨ í™•ì¸

## ê°œìš”

ìƒí™©ë¶„ì„ APIëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë²•ì  ìƒí™©ì„ ë¶„ì„í•˜ì—¬ ë²•ì  ë¦¬ìŠ¤í¬, íŒë‹¨ ê¸°ì¤€, í–‰ë™ ê°€ì´ë“œ ë“±ì„ ì œê³µí•˜ëŠ” APIì…ë‹ˆë‹¤. LangGraph ê¸°ë°˜ì˜ ë©€í‹° ìŠ¤í… ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•˜ê³  ì²´ê³„ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

## API ì—”ë“œí¬ì¸íŠ¸

### POST `/api/v2/legal/analyze-situation`

**ìœ„ì¹˜**: `backend/api/routes_legal_v2.py` (1228-1665ì¤„)

**ìš”ì²­ íŒŒë¼ë¯¸í„°**:
```typescript
{
  situation: string;              // ìƒí™© ì„¤ëª… í…ìŠ¤íŠ¸
  category?: string;              // ì¹´í…Œê³ ë¦¬ íŒíŠ¸
  employmentType?: string;        // ê³ ìš© í˜•íƒœ
  companySize?: string;           // íšŒì‚¬ ê·œëª¨
  workPeriod?: string;            // ê·¼ë¬´ ê¸°ê°„
  hasWrittenContract?: boolean;   // ê³„ì•½ì„œ ë³´ìœ  ì—¬ë¶€
  socialInsurance?: string[];     // ì‚¬íšŒë³´í—˜ ê°€ì… í˜„í™©
}
```

**ì‘ë‹µ êµ¬ì¡°**:
```typescript
{
  id: string;                     // DB ì €ì¥ í›„ ìƒì„±ëœ ID
  riskScore: number;               // ìœ„í—˜ë„ ì ìˆ˜ (0-100)
  riskLevel: "low" | "medium" | "high";  // ìœ„í—˜ë„ ë ˆë²¨
  tags: string[];                 // ë¶„ë¥˜ íƒœê·¸
  summary: string;                 // ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë¦¬í¬íŠ¸
  findings: Finding[];            // ë²•ì  ìŸì  ë°œê²¬ í•­ëª©
  relatedCases: RelatedCase[];     // ê´€ë ¨ ì‚¬ë¡€ (ë¬¸ì„œ ë‹¨ìœ„)
  scripts: ScriptsV2;             // ì´ë©”ì¼ í…œí”Œë¦¿
  organizations: Organization[];   // ì¶”ì²œ ê¸°ê´€ ëª©ë¡
}
```

## ì „ì²´ ì²˜ë¦¬ íë¦„

```
1. API ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì‹  (routes_legal_v2.py)
   â†“
2. LegalRAGService.analyze_situation_detailed() í˜¸ì¶œ
   â†“
3. SituationWorkflow.run() ì‹¤í–‰ (LangGraph ì›Œí¬í”Œë¡œìš°)
   â†“
4. ì›Œí¬í”Œë¡œìš° ê²°ê³¼ ë³€í™˜ ë° DB ì €ì¥
   â†“
5. ìµœì¢… ì‘ë‹µ ë°˜í™˜
```

## ìƒì„¸ ì²˜ë¦¬ ì ˆì°¨

### 1ë‹¨ê³„: API ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì‹  ë° ê²€ì¦

**íŒŒì¼**: `backend/api/routes_legal_v2.py` (1228-1255ì¤„)

```1228:1255:backend/api/routes_legal_v2.py
@router.post("/analyze-situation", response_model=dict)
async def analyze_situation(
    payload: SituationRequestV2,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒí™© ì„¤ëª… + ë©”íƒ€ ì •ë³´ â†’ ë§ì¶¤í˜• ìƒë‹´ ë¶„ì„
    """
    # loggerë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì°¸ì¡° (ìŠ¤ì½”í”„ ë¬¸ì œ ë°©ì§€)
    import logging
    _logger = logging.getLogger(__name__)
    
    try:
        service = get_legal_service()
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš© (RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë” ì •í™•í•˜ê²Œ í™œìš©)
        result = await service.analyze_situation_detailed(
            category_hint=payload.category or "unknown",
            situation_text=payload.situation,
            summary=None,
            details=None,
            employment_type=payload.employmentType,
            work_period=payload.workPeriod,
            weekly_hours=None,
            is_probation=None,
            social_insurance=", ".join(payload.socialInsurance) if payload.socialInsurance else None,
            use_workflow=True,  # ì›Œí¬í”Œë¡œìš° í™œì„±í™”: ë¶„ë¥˜ â†’ í•„í„°ë§ â†’ RAG ê²€ìƒ‰ â†’ ë¦¬í¬íŠ¸ ìƒì„±
        )
```

**ì²˜ë¦¬ ë‚´ìš©**:
- ìš”ì²­ íŒŒë¼ë¯¸í„° ê²€ì¦
- `LegalRAGService` ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
- `analyze_situation_detailed()` í˜¸ì¶œ (ì›Œí¬í”Œë¡œìš° í™œì„±í™”)

### 2ë‹¨ê³„: LegalRAGService.analyze_situation_detailed()

**íŒŒì¼**: `backend/core/legal_rag_service.py` (201-264ì¤„)

```201:264:backend/core/legal_rag_service.py
    async def analyze_situation_detailed(
        self,
        category_hint: str,
        situation_text: str,
        summary: Optional[str] = None,
        details: Optional[str] = None,
        employment_type: Optional[str] = None,
        work_period: Optional[str] = None,
        weekly_hours: Optional[int] = None,
        is_probation: Optional[bool] = None,
        social_insurance: Optional[str] = None,
        use_workflow: bool = False,  # LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš© ì—¬ë¶€
    ) -> dict:
        """
        ìƒí™© ê¸°ë°˜ ìƒì„¸ ì§„ë‹¨
        
        Args:
            use_workflow: Trueë©´ LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©, Falseë©´ ê¸°ì¡´ ë‹¨ì¼ ìŠ¤í… ë°©ì‹
        
        Returns:
            {
                "classified_type": str,
                "risk_score": int,
                "summary": str,
                "criteria": List[CriteriaItem],
                "action_plan": ActionPlan,
                "scripts": Scripts,
                "related_cases": List[RelatedCase]
            }
        """
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©
        if use_workflow:
            try:
                from core.situation_workflow import SituationWorkflow
                workflow = SituationWorkflow()
                initial_state = {
                    "situation_text": situation_text,
                    "category_hint": category_hint,
                    "summary": summary,
                    "details": details,
                    "employment_type": employment_type,
                    "work_period": work_period,
                    "weekly_hours": weekly_hours,
                    "is_probation": is_probation,
                    "social_insurance": social_insurance,
                }
                result = await workflow.run(initial_state)
                logger.info("[ìƒí™©ë¶„ì„] LangGraph ì›Œí¬í”Œë¡œìš°ë¡œ ë¶„ì„ ì™„ë£Œ")
                
                # ì›Œí¬í”Œë¡œìš° ê²°ê³¼ê°€ final_output ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
                # final_outputì—ëŠ” summary, findings, organizations ë“±ì´ í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•¨
                if not isinstance(result, dict):
                    logger.warning(f"[ìƒí™©ë¶„ì„] ì›Œí¬í”Œë¡œìš° ê²°ê³¼ê°€ dictê°€ ì•„ë‹˜: {type(result)}")
                    result = {}
                
                # findingsì™€ organizationsê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •
                if "findings" not in result:
                    logger.warning("[ìƒí™©ë¶„ì„] ì›Œí¬í”Œë¡œìš° ê²°ê³¼ì— findings í•„ë“œê°€ ì—†ìŒ, ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •")
                    result["findings"] = []
                if "organizations" not in result:
                    logger.warning("[ìƒí™©ë¶„ì„] ì›Œí¬í”Œë¡œìš° ê²°ê³¼ì— organizations í•„ë“œê°€ ì—†ìŒ, ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •")
                    result["organizations"] = []
                
                return result
```

**ì²˜ë¦¬ ë‚´ìš©**:
- `SituationWorkflow` ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
- ì´ˆê¸° ìƒíƒœ êµ¬ì„±
- ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
- ê²°ê³¼ ê²€ì¦ ë° ë°˜í™˜

### 3ë‹¨ê³„: LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

**íŒŒì¼**: `backend/core/situation_workflow.py`

ì›Œí¬í”Œë¡œìš°ëŠ” ë‹¤ìŒ 7ê°œì˜ ë…¸ë“œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

#### 3-1. prepare_query_node: ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì¤€ë¹„ ë° ì„ë² ë”© ìƒì„±

```126:144:backend/core/situation_workflow.py
    async def prepare_query_node(self, state: SituationWorkflowState) -> SituationWorkflowState:
        """1. ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì¤€ë¹„ ë° ì„ë² ë”© ìƒì„±"""
        logger.info("[ì›Œí¬í”Œë¡œìš°] prepare_query_node ì‹œì‘")
        
        # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ êµ¬ì„±
        query_text = state.get("situation_text", "")
        if state.get("summary"):
            query_text = state["summary"]
            if state.get("details"):
                query_text = f"{state['summary']}\n\n{state['details']}"
        
        # ì„ë² ë”© ìƒì„±
        query_embedding = await self._get_embedding(query_text)
        
        return {
            **state,
            "query_text": query_text,
            "query_embedding": query_embedding,
        }
```

**ì²˜ë¦¬ ë‚´ìš©**:
- ìƒí™© í…ìŠ¤íŠ¸ ë˜ëŠ” summary+details ì¡°í•©ìœ¼ë¡œ ì¿¼ë¦¬ êµ¬ì„±
- í…ìŠ¤íŠ¸ ì„ë² ë”© ë²¡í„° ìƒì„±

#### 3-2. classify_situation_node: ìƒí™© ë¶„ë¥˜

```146:167:backend/core/situation_workflow.py
    async def classify_situation_node(self, state: SituationWorkflowState) -> SituationWorkflowState:
        """2. ìƒí™© ë¶„ë¥˜ (ì¹´í…Œê³ ë¦¬ + ìœ„í—˜ë„)"""
        logger.info("[ì›Œí¬í”Œë¡œìš°] classify_situation_node ì‹œì‘")
        
        query_text = state.get("query_text", "")
        category_hint = state.get("category_hint")
        
        # LLMìœ¼ë¡œ ë¶„ë¥˜ ìˆ˜í–‰
        classification = await self._llm_classify(
            situation_text=query_text,
            category_hint=category_hint,
            employment_type=state.get("employment_type"),
            work_period=state.get("work_period"),
            weekly_hours=state.get("weekly_hours"),
            is_probation=state.get("is_probation"),
            social_insurance=state.get("social_insurance"),
        )
        
        return {
            **state,
            "classification": classification,
        }
```

**ì²˜ë¦¬ ë‚´ìš©**:
- LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒí™© ë¶„ë¥˜ (classified_type, risk_score)
- ì‚¬ìš©ì ë©”íƒ€ ì •ë³´(ê³ ìš© í˜•íƒœ, ê·¼ë¬´ ê¸°ê°„ ë“±) í™œìš©

#### 3-3. filter_rules_node: ê·œì • í•„í„°ë§

```169:185:backend/core/situation_workflow.py
    async def filter_rules_node(self, state: SituationWorkflowState) -> SituationWorkflowState:
        """3. ë¶„ë¥˜ ê²°ê³¼ ê¸°ë°˜ ê·œì • í•„í„°ë§"""
        logger.info("[ì›Œí¬í”Œë¡œìš°] filter_rules_node ì‹œì‘")
        
        classification = state.get("classification", {})
        classified_type = classification.get("classified_type", "unknown")
        
        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„°ë§ ê·œì¹™ ìƒì„±
        filtered_categories = await self._filter_rules_by_classification(
            classified_type=classified_type,
            classification=classification,
        )
        
        return {
            **state,
            "filtered_categories": filtered_categories,
        }
```

**ì²˜ë¦¬ ë‚´ìš©**:
- ë¶„ë¥˜ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•  ë²•ë ¹ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
- ë¶ˆí•„ìš”í•œ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œë¡œ ì •í™•ë„ í–¥ìƒ

#### 3-4. retrieve_guides_node: RAG ê²€ìƒ‰

```187:233:backend/core/situation_workflow.py
    async def retrieve_guides_node(self, state: SituationWorkflowState) -> SituationWorkflowState:
        """4. RAG ê²€ìƒ‰ (í•„í„°ë§ëœ ì¹´í…Œê³ ë¦¬ë§Œ) + legalBasis ì¶”ì¶œ"""
        logger.info("[ì›Œí¬í”Œë¡œìš°] retrieve_guides_node ì‹œì‘")
        
        query_embedding = state.get("query_embedding")
        filtered_categories = state.get("filtered_categories", [])
        
        if not query_embedding:
            logger.warning("[ì›Œí¬í”Œë¡œìš°] query_embeddingì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return {
                **state,
                "grounding_chunks": [],
                "related_cases": [],
                "legal_basis": [],
            }
        
        # ë³‘ë ¬ ê²€ìƒ‰
        grounding_chunks, related_cases = await asyncio.gather(
            self._search_legal_with_filter(
                query_embedding=query_embedding,
                categories=filtered_categories,
                top_k=8,
            ),
            self._search_cases_with_embedding(
                query_embedding=query_embedding,
                top_k=3,
            ),
            return_exceptions=False
        )
        
        # RAG ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…
        logger.info(f"[ì›Œí¬í”Œë¡œìš°] RAG ê²€ìƒ‰ ì™„ë£Œ: ë²•ë ¹/ê°€ì´ë“œ {len(grounding_chunks)}ê°œ, ì¼€ì´ìŠ¤ {len(related_cases)}ê°œ")
        if grounding_chunks:
            logger.info(f"[ì›Œí¬í”Œë¡œìš°] ê²€ìƒ‰ëœ ë²•ë ¹/ê°€ì´ë“œ ëª©ë¡:")
            for idx, chunk in enumerate(grounding_chunks[:5], 1):  # ìƒìœ„ 5ê°œë§Œ ë¡œê¹…
                logger.info(f"  {idx}. [{chunk.source_type}] {chunk.title} (score: {chunk.score:.3f})")
                logger.info(f"     ë‚´ìš©: {chunk.snippet[:100]}...")
        
        # legalBasis êµ¬ì¡° ì¶”ì¶œ (criteria ê°€ê³µìš©)
        legal_basis = self._extract_legal_basis(grounding_chunks)
        
        return {
            **state,
            "grounding_chunks": grounding_chunks,
            "related_cases": related_cases[:3],  # ìµœëŒ€ 3ê°œë§Œ
            "legal_basis": legal_basis,
        }
```

**ì²˜ë¦¬ ë‚´ìš©**:
- í•„í„°ë§ëœ ì¹´í…Œê³ ë¦¬ë¡œ ë²•ë ¹/ê°€ì´ë“œ ë²¡í„° ê²€ìƒ‰ (top_k=8)
- ê´€ë ¨ ì¼€ì´ìŠ¤ ë²¡í„° ê²€ìƒ‰ (top_k=3)
- ë³‘ë ¬ ê²€ìƒ‰ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
- legal_basis êµ¬ì¡° ì¶”ì¶œ (criteria ìƒì„±ìš©)

#### 3-5. generate_all_fields_node: ëª¨ë“  í•„ë“œ ë³‘ë ¬ ìƒì„±

```235:328:backend/core/situation_workflow.py
    async def generate_all_fields_node(self, state: SituationWorkflowState) -> SituationWorkflowState:
        """5. ëª¨ë“  í•„ë“œ ë³‘ë ¬ ìƒì„± (summary, findings, scripts, organizations)"""
        logger.info("[ì›Œí¬í”Œë¡œìš°] generate_all_fields_node ì‹œì‘ - ë³‘ë ¬ ì‹¤í–‰")
        
        classification = state.get("classification", {})
        grounding_chunks = state.get("grounding_chunks", [])
        legal_basis = state.get("legal_basis", [])
        query_text = state.get("query_text", "")
        
        logger.info(f"[ì›Œí¬í”Œë¡œìš°] ì…ë ¥ ë°ì´í„° í™•ì¸ - classification: {bool(classification)}, grounding_chunks: {len(grounding_chunks)}ê°œ, legal_basis: {len(legal_basis)}ê°œ, query_text ê¸¸ì´: {len(query_text)}ì")
        
        # legal_basisê°€ ë¹ˆ ë°°ì—´ì¼ ë•Œ fallback
        if not legal_basis:
            logger.warning("[ì›Œí¬í”Œë¡œìš°] legal_basisê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ criteria ìƒì„±")
            legal_basis = [{
                "title": "ë²•ì  ê·¼ê±° í™•ì¸ í•„ìš”",
                "snippet": "ê´€ë ¨ ë²•ë ¹ ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.",
                "source_type": "unknown",
            }]
        
        # ë³‘ë ¬ë¡œ ëª¨ë“  í•„ë“œ ìƒì„±
        logger.info("[ì›Œí¬í”Œë¡œìš°] ë³‘ë ¬ LLM í˜¸ì¶œ ì‹œì‘ (summary, findings, scripts, organizations)...")
        start_time = asyncio.get_event_loop().time()
        
        summary_result, findings_result, scripts_result, organizations_result = await asyncio.gather(
            self._llm_generate_summary(
                situation_text=query_text,
                classification=classification,
                grounding_chunks=grounding_chunks,
                legal_basis=legal_basis,
                employment_type=state.get("employment_type"),
                work_period=state.get("work_period"),
                weekly_hours=state.get("weekly_hours"),
                is_probation=state.get("is_probation"),
                social_insurance=state.get("social_insurance"),
            ),
            self._llm_generate_findings(
                situation_text=query_text,
                classification=classification,
                grounding_chunks=grounding_chunks,
                legal_basis=legal_basis,
                employment_type=state.get("employment_type"),
                work_period=state.get("work_period"),
                weekly_hours=state.get("weekly_hours"),
                is_probation=state.get("is_probation"),
                social_insurance=state.get("social_insurance"),
            ),
            self._llm_generate_scripts(
                situation_text=query_text,
                classification=classification,
                grounding_chunks=grounding_chunks,
                legal_basis=legal_basis,
                employment_type=state.get("employment_type"),
                work_period=state.get("work_period"),
                weekly_hours=state.get("weekly_hours"),
                is_probation=state.get("is_probation"),
                social_insurance=state.get("social_insurance"),
            ),
            self._llm_generate_organizations(
                situation_text=query_text,
                classification=classification,
            ),
            return_exceptions=True
        )
        
        elapsed_time = asyncio.get_event_loop().time() - start_time
        logger.info(f"[ì›Œí¬í”Œë¡œìš°] ë³‘ë ¬ LLM í˜¸ì¶œ ì™„ë£Œ - ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        if isinstance(summary_result, Exception):
            logger.error(f"[ì›Œí¬í”Œë¡œìš°] summary ìƒì„± ì‹¤íŒ¨: {summary_result}", exc_info=summary_result)
            # ê¸°ë³¸ summary ë°˜í™˜ (4ê°œ ì„¹ì…˜ êµ¬ì¡° ìœ ì§€)
            summary_result = "## ğŸ“Š ìƒí™© ë¶„ì„ì˜ ê²°ê³¼\n\nìƒí™©ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²•ì  ê´€ì ê³¼ í–‰ë™ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n\n## âš–ï¸ ë²•ì  ê´€ì ì—ì„œ ë³¸ í˜„ì¬ ìƒí™©\n\nê´€ë ¨ ë²•ë ¹ì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.\n\n## ğŸ¯ ì§€ê¸ˆ ë‹¹ì¥ í•  ìˆ˜ ìˆëŠ” í–‰ë™\n\n- ìƒí™©ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”\n- ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”\n\n## ğŸ’¬ ì´ë ‡ê²Œ ë§í•´ë³´ì„¸ìš”\n\nìƒë‹´ ê¸°ê´€ì— ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        elif not summary_result or (isinstance(summary_result, str) and len(summary_result.strip()) == 0):
            logger.warning("[ì›Œí¬í”Œë¡œìš°] summaryê°€ ë¹„ì–´ìˆìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
            summary_result = "## ğŸ“Š ìƒí™© ë¶„ì„ì˜ ê²°ê³¼\n\nìƒí™©ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²•ì  ê´€ì ê³¼ í–‰ë™ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n\n## âš–ï¸ ë²•ì  ê´€ì ì—ì„œ ë³¸ í˜„ì¬ ìƒí™©\n\nê´€ë ¨ ë²•ë ¹ì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.\n\n## ğŸ¯ ì§€ê¸ˆ ë‹¹ì¥ í•  ìˆ˜ ìˆëŠ” í–‰ë™\n\n- ìƒí™©ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”\n- ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”\n\n## ğŸ’¬ ì´ë ‡ê²Œ ë§í•´ë³´ì„¸ìš”\n\nìƒë‹´ ê¸°ê´€ì— ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        if isinstance(findings_result, Exception):
            logger.error(f"[ì›Œí¬í”Œë¡œìš°] findings ìƒì„± ì‹¤íŒ¨: {findings_result}", exc_info=findings_result)
            findings_result = []
        if isinstance(scripts_result, Exception):
            logger.error(f"[ì›Œí¬í”Œë¡œìš°] scripts ìƒì„± ì‹¤íŒ¨: {scripts_result}", exc_info=scripts_result)
            scripts_result = {}
        if isinstance(organizations_result, Exception):
            logger.error(f"[ì›Œí¬í”Œë¡œìš°] organizations ìƒì„± ì‹¤íŒ¨: {organizations_result}", exc_info=organizations_result)
            organizations_result = []
        
        return {
            **state,
            "summary_report": summary_result if isinstance(summary_result, str) else "",
            "scripts": scripts_result if isinstance(scripts_result, dict) else {},
            "findings": findings_result if isinstance(findings_result, list) else [],
            "organizations": organizations_result if isinstance(organizations_result, list) else [],
        }
```

**ì²˜ë¦¬ ë‚´ìš©**:
- **ë³‘ë ¬ LLM í˜¸ì¶œ**ë¡œ ë‹¤ìŒ 4ê°œ í•„ë“œë¥¼ ë™ì‹œì— ìƒì„±:
  1. `summary`: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë¦¬í¬íŠ¸ (4ê°œ ì„¹ì…˜: ğŸ“Š ìƒí™© ë¶„ì„, âš–ï¸ ë²•ì  íŒë‹¨, ğŸ”® ì˜ˆìƒ ì‹œë‚˜ë¦¬ì˜¤, ğŸ’¡ ì£¼ì˜ì‚¬í•­)
  2. `findings`: ë²•ì  ìŸì  ë°œê²¬ í•­ëª© ë¦¬ìŠ¤íŠ¸
  3. `scripts`: ì´ë©”ì¼ í…œí”Œë¦¿ (to_company, to_advisor)
  4. `organizations`: ì¶”ì²œ ê¸°ê´€ ëª©ë¡
- ì˜ˆì™¸ ì²˜ë¦¬ ë° ê¸°ë³¸ê°’ ì„¤ì •

#### 3-6. merge_output_node: ìµœì¢… ì¶œë ¥ ë³‘í•©

```389:652:backend/core/situation_workflow.py
    async def merge_output_node(self, state: SituationWorkflowState) -> SituationWorkflowState:
        """7. ìµœì¢… ì¶œë ¥ ë³‘í•©"""
        logger.info("[ì›Œí¬í”Œë¡œìš°] merge_output_node ì‹œì‘")
        
        classification = state.get("classification", {})
        related_cases = state.get("related_cases", [])
        action_plan = state.get("action_plan", {})
        scripts = state.get("scripts", {})
        criteria = state.get("criteria", [])
        findings = state.get("findings", [])  # ë²•ì  ìŸì  ë°œê²¬ í•­ëª©
        organizations = state.get("organizations", [])  # ì¶”ì²œ ê¸°ê´€ ëª©ë¡
        summary_report = state.get("summary_report", "")  # generate_action_guideì—ì„œ ìƒì„±ë¨
        legal_basis = state.get("legal_basis", [])  # legal_basis ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        # grounding_chunks ê°€ì ¸ì˜¤ê¸°
        grounding_chunks = state.get("grounding_chunks", [])
        
        # ìµœì¢… JSON ì¶œë ¥ êµ¬ì„±
        # related_casesëŠ” ì´ë¯¸ retrieve_guidesì—ì„œ ìµœëŒ€ 3ê°œë¡œ ì œí•œë¨
        # related_casesëŠ” dict í˜•íƒœë¡œ ë°˜í™˜ë˜ë¯€ë¡œ dict ì ‘ê·¼ ë°©ì‹ ì‚¬ìš©
        formatted_related_cases = []
        for case in related_cases[:3]:  # ìµœëŒ€ 3ê°œë§Œ (ì´ì¤‘ ì•ˆì „ì¥ì¹˜)
            if isinstance(case, dict):
                case_id = case.get("id", "")
                case_title = case.get("title", "")
                case_situation = case.get("situation", "")
                case_source_type = case.get("source_type")
            else:
                # ê°ì²´ì¸ ê²½ìš° (Legacy ì§€ì›)
                case_id = getattr(case, "id", "")
                case_title = getattr(case, "title", "")
                case_situation = getattr(case, "situation", "")
                case_source_type = getattr(case, "source_type", None)
            
            formatted_related_cases.append({
                "id": case_id,  # external_id
                "title": case_title,
                "summary": case_situation[:200] if len(case_situation) > 200 else case_situation,
                "source_type": case_source_type,  # source_type ì •ë³´ ì¶”ê°€
            })
        
        # grounding_chunksë¥¼ sources í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted_sources = [
            {
                "source_id": chunk.source_id,
                "source_type": chunk.source_type,
                "title": chunk.title,
                "snippet": chunk.snippet,
                "score": chunk.score,
                "external_id": getattr(chunk, 'external_id', None),
                "file_url": getattr(chunk, 'file_url', None),
            }
            for chunk in grounding_chunks[:8]  # ìµœëŒ€ 8ê°œ
        ]
        
        # criteriaë¥¼ grounding_chunksì—ì„œ ì§ì ‘ ìƒì„± (ìƒˆë¡œìš´ RAG ê¸°ë°˜ êµ¬ì¡°)
        # grounding_chunksë¥¼ criteria í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        from core.file_utils import get_document_file_url
        
        criteria_items = []
        for chunk in grounding_chunks[:8]:  # ìµœëŒ€ 8ê°œ
            external_id = getattr(chunk, 'external_id', None)
            source_type = chunk.source_type
            file_url = getattr(chunk, 'file_url', None)
            
            # file_urlì´ ì—†ìœ¼ë©´ ìƒì„± (external_idê°€ ìˆëŠ” ê²½ìš°)
            if not file_url and external_id:
                try:
                    file_url = get_document_file_url(
                        external_id=external_id,
                        source_type=source_type,
                        expires_in=3600
                    )
                except Exception as e:
                    logger.warning(f"[ì›Œí¬í”Œë¡œìš°] fileUrl ìƒì„± ì‹¤íŒ¨ (external_id={external_id}, source_type={source_type}): {str(e)}")
                    file_url = None
            
            # usageReason ìƒì„± (ìš°ì„ ìˆœìœ„: LLM criteria reason > snippet ê¸°ë°˜ êµ¬ì²´ì  ìƒì„± > ê¸°ë³¸ ë©”ì‹œì§€)
            usage_reason = ""
            chunk_snippet_prefix = chunk.snippet[:50].strip() if chunk.snippet else ""
            chunk_snippet = chunk.snippet[:200].strip() if chunk.snippet else ""
            
            # 1. LLMì´ ìƒì„±í•œ criteriaì—ì„œ í•´ë‹¹ ë¬¸ì„œì™€ ê´€ë ¨ëœ reason ì°¾ê¸°
            for criterion in criteria:
                if isinstance(criterion, dict):
                    criterion_name = criterion.get("name", "")
                    criterion_reason = criterion.get("reason", "")
                    criterion_legal_basis = criterion.get("legalBasis", [])
                    
                    # ë¬¸ì„œ ì œëª© ë§¤ì¹­
                    if chunk.title in criterion_name or criterion_name in chunk.title:
                        # reasonì´ ë„ˆë¬´ ê¸¸ë©´ (snippet ì „ì²´ê°€ ë“¤ì–´ê°„ ê²½ìš°) ë‹¤ìŒ ë‹¨ê³„ë¡œ
                        if len(criterion_reason) > 200:
                            break
                        # ì¼ë°˜ì ì¸ í…œí”Œë¦¿ ë¬¸ì¥ì¸ì§€ í™•ì¸ ("í˜„ì¬ ìƒí™©ê³¼ ê´€ë ¨í•˜ì—¬", "ë²•ì  íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤" ë“±)
                        elif "í˜„ì¬ ìƒí™©ê³¼ ê´€ë ¨í•˜ì—¬" in criterion_reason and "ë²•ì  íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤" in criterion_reason:
                            # ì¼ë°˜ì ì¸ ë¬¸ì¥ì´ë©´ snippet ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì  ìƒì„± ì‹œë„
                            break
                        else:
                            usage_reason = criterion_reason
                            break
                    
                    # legalBasisì—ì„œ snippet ë§¤ì¹­ ì‹œë„
                    if criterion_legal_basis and isinstance(criterion_legal_basis, list):
                        for basis in criterion_legal_basis:
                            if isinstance(basis, dict):
                                basis_snippet = basis.get("snippet", "")
                                if chunk_snippet_prefix and basis_snippet:
                                    if chunk_snippet_prefix[:30] in basis_snippet[:100] or basis_snippet[:30] in chunk_snippet_prefix[:100]:
                                        # ì¼ë°˜ì ì¸ í…œí”Œë¦¿ ë¬¸ì¥ì¸ì§€ í™•ì¸
                                        if "í˜„ì¬ ìƒí™©ê³¼ ê´€ë ¨í•˜ì—¬" in criterion_reason and "ë²•ì  íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤" in criterion_reason:
                                            break
                                        else:
                                            usage_reason = criterion_reason if len(criterion_reason) <= 200 else ""
                                            break
                        if usage_reason:
                            break
                else:
                    criterion_name = getattr(criterion, "name", "")
                    criterion_reason = getattr(criterion, "reason", "")
                    if chunk.title in criterion_name or criterion_name in chunk.title:
                        # ì¼ë°˜ì ì¸ í…œí”Œë¦¿ ë¬¸ì¥ì¸ì§€ í™•ì¸
                        if "í˜„ì¬ ìƒí™©ê³¼ ê´€ë ¨í•˜ì—¬" in criterion_reason and "ë²•ì  íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤" in criterion_reason:
                            break
                        usage_reason = criterion_reason if len(criterion_reason) <= 200 else ""
                        if usage_reason:
                            break
            
            # 2. snippet ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì¸ usageReason ìƒì„± (LLM reasonì´ ì—†ê±°ë‚˜ ì¼ë°˜ì ì¸ ê²½ìš°)
            if not usage_reason and chunk_snippet:
                # snippetì—ì„œ í•µì‹¬ ìŸì  í‚¤ì›Œë“œ ì¶”ì¶œ
                issue_keywords = []
                if any(kw in chunk_snippet for kw in ["í–‰ì‚¬ê¸°ê°„", "í–‰ì‚¬ ê¸°ê°„", "í–‰ì‚¬ê¸°í•œ"]):
                    issue_keywords.append("í–‰ì‚¬ê¸°ê°„")
                if any(kw in chunk_snippet for kw in ["ì¬ì§", "ì¬ì„", "ê·¼ë¬´ê¸°ê°„"]):
                    issue_keywords.append("ì¬ì§ìš”ê±´")
                if any(kw in chunk_snippet for kw in ["í•´ê³ ", "ê³„ì•½í•´ì§€", "í•´ì§€"]):
                    issue_keywords.append("í•´ê³  ì˜ˆê³ ")
                if any(kw in chunk_snippet for kw in ["ì„ ê¸‰ê¸ˆ", "ì„ ê¸ˆ", "ê³„ì•½ê¸ˆ"]):
                    issue_keywords.append("ì„ ê¸‰ê¸ˆ")
                if any(kw in chunk_snippet for kw in ["ì§€ì—°", "ë°°ìƒ", "ì´ì"]):
                    issue_keywords.append("ì§€ì—°ë°°ìƒ")
                if any(kw in chunk_snippet for kw in ["ì„ê¸ˆ", "ê¸‰ì—¬", "ì§€ê¸‰ì¼"]):
                    issue_keywords.append("ì„ê¸ˆì§€ê¸‰ì¼")
                if any(kw in chunk_snippet for kw in ["ìˆ˜ìŠµ", "ìˆ˜ìŠµê¸°ê°„"]):
                    issue_keywords.append("ìˆ˜ìŠµê¸°ê°„")
                if any(kw in chunk_snippet for kw in ["ì—°ì¥ê·¼ë¡œ", "ì•¼ê°„ê·¼ë¡œ", "íœ´ì¼ê·¼ë¡œ"]):
                    issue_keywords.append("ì—°ì¥ê·¼ë¡œìˆ˜ë‹¹")
                
                # snippet í•µì‹¬ ë‚´ìš© ìš”ì•½ (ì²« 100ì)
                snippet_summary = chunk_snippet[:100].replace("\n", " ").strip()
                
                # ë¬¸ì„œ íƒ€ì…ì— ë”°ë¥¸ íŒë‹¨ í¬ì¸íŠ¸
                if issue_keywords:
                    issue_text = ", ".join(issue_keywords[:2])  # ìµœëŒ€ 2ê°œë§Œ
                    if "í‘œì¤€" in chunk.title and "ê³„ì•½" in chunk.title:
                        usage_reason = f"ì´ ì¡°í•­ì€ {issue_text}ì— ëŒ€í•œ ê·œì •ì„ í¬í•¨í•˜ê³  ìˆì–´, í˜„ì¬ ì‚¬ìš©ì ê³„ì•½ì„œì˜ í•´ë‹¹ ì¡°í•­ì´ ë¶ˆëª…í™•í•˜ê±°ë‚˜ ê³¼ë„í•˜ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ ë¹„êµÂ·íŒë‹¨í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
                    elif "ë²•" in chunk.title or "ê·œì¹™" in chunk.title:
                        usage_reason = f"ì´ ì¡°í•­ì€ {issue_text}ì— ëŒ€í•œ ë²•ì  ìš”ê±´ì„ ê·œì •í•˜ê³  ìˆì–´, í˜„ì¬ ìƒí™©ì—ì„œ í•´ë‹¹ ìš”ê±´ì´ ì¶©ì¡±ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” ê·¼ê±°ë¡œ í™œìš©í–ˆìŠµë‹ˆë‹¤."
                    else:
                        usage_reason = f"ì´ ì¡°í•­ì€ {issue_text}ì— ëŒ€í•œ ë‚´ìš©ì„ ë‹¤ë£¨ê³  ìˆì–´, í˜„ì¬ ì‚¬ìš©ì ìƒí™©/ê³„ì•½ì„œì—ì„œ í•´ë‹¹ ë¶€ë¶„ì„ í‰ê°€í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
                else:
                    # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ snippet ìš”ì•½ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
                    if "í‘œì¤€" in chunk.title and "ê³„ì•½" in chunk.title:
                        usage_reason = f"ì´ ì¡°í•­ì€ '{snippet_summary}...'ì˜ ë‚´ìš©ì„ ê·œì •í•˜ê³  ìˆì–´, í˜„ì¬ ê³„ì•½ì„œì˜ ê´€ë ¨ ì¡°í•­ê³¼ ë¹„êµí•˜ì—¬ ì ì ˆì„±ì„ íŒë‹¨í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
                    elif "ë²•" in chunk.title or "ê·œì¹™" in chunk.title:
                        usage_reason = f"ì´ ì¡°í•­ì€ '{snippet_summary}...'ì˜ ë²•ì  ìš”ê±´ì„ ëª…ì‹œí•˜ê³  ìˆì–´, í˜„ì¬ ìƒí™©ì—ì„œ í•´ë‹¹ ìš”ê±´ ì¶©ì¡± ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ê·¼ê±°ë¡œ í™œìš©í–ˆìŠµë‹ˆë‹¤."
                    else:
                        usage_reason = f"ì´ ì¡°í•­ì€ '{snippet_summary}...'ì˜ ë‚´ìš©ì„ í¬í•¨í•˜ê³  ìˆì–´, í˜„ì¬ ì‚¬ìš©ì ìƒí™©ê³¼ ë¹„êµí•˜ì—¬ í‰ê°€í•˜ëŠ” ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
            
            # 3. usageReasonì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€ ìƒì„± (ìµœí›„ì˜ ìˆ˜ë‹¨)
            if not usage_reason:
                if "í‘œì¤€" in chunk.title and "ê³„ì•½" in chunk.title:
                    usage_reason = f"í˜„ì¬ ê³„ì•½ì„œì˜ ê´€ë ¨ ì¡°í•­ì´ ë¶ˆëª…í™•í•œ ë¶€ë¶„ì´ ìˆì–´, {chunk.title}ì˜ ê·œì •ì„ ë¹„êµ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
                elif "ë²•" in chunk.title or "ê·œì¹™" in chunk.title:
                    usage_reason = f"í˜„ì¬ ìƒí™©ê³¼ ê´€ë ¨í•˜ì—¬ {chunk.title}ì˜ ë²•ë ¹ ì¡°í•­ì„ íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
                else:
                    usage_reason = f"í˜„ì¬ ìƒí™©ê³¼ ê´€ë ¨í•˜ì—¬ {chunk.title}ì˜ ë‚´ìš©ì„ ë²•ì  íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
            
            criteria_item = {
                "documentTitle": chunk.title,
                "fileUrl": file_url,
                "sourceType": source_type,
                "similarityScore": float(chunk.score),
                "snippet": chunk.snippet,
                "usageReason": usage_reason,
            }
            criteria_items.append(criteria_item)
        
        # findings ì²˜ë¦¬: LLMì´ ìƒì„±í•œ findingsë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜, source ì •ë³´ ë³´ì™„
        findings_processed = []
        if findings:
            logger.info(f"[ì›Œí¬í”Œë¡œìš°] findings ì²˜ë¦¬ ì‹œì‘: {len(findings)}ê°œ")
            for idx, finding in enumerate(findings):
                if not isinstance(finding, dict):
                    logger.warning(f"[ì›Œí¬í”Œë¡œìš°] finding[{idx}]ì´ dictê°€ ì•„ë‹˜: {type(finding)}")
                    continue
                
                # source ì •ë³´ ë³´ì™„ (fileUrlì´ ì—†ìœ¼ë©´ ìƒì„±)
                source = finding.get("source", {})
                if not isinstance(source, dict):
                    logger.warning(f"[ì›Œí¬í”Œë¡œìš°] finding[{idx}] sourceê°€ dictê°€ ì•„ë‹˜: {type(source)}")
                    source = {}
                
                document_title = source.get("documentTitle", "").strip()
                source_type = source.get("sourceType", "law")
                external_id = None
                
                # grounding_chunksì—ì„œ í•´ë‹¹ ë¬¸ì„œ ì°¾ì•„ì„œ external_id ë° fileUrl ë³´ì™„
                for chunk in grounding_chunks:
                    if document_title and (chunk.title == document_title or document_title in chunk.title):
                        external_id = getattr(chunk, 'external_id', None)
                        source_type = chunk.source_type  # grounding_chunksì˜ source_type ì‚¬ìš©
                        if not source.get("fileUrl") and external_id:
                            try:
                                from core.file_utils import get_document_file_url
                                file_url = get_document_file_url(
                                    external_id=external_id,
                                    source_type=source_type,
                                    expires_in=3600
                                )
                                source["fileUrl"] = file_url
                                logger.debug(f"[ì›Œí¬í”Œë¡œìš°] finding[{idx}] fileUrl ìƒì„±: {file_url[:50]}...")
                            except Exception as e:
                                logger.warning(f"[ì›Œí¬í”Œë¡œìš°] finding[{idx}] source fileUrl ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        # similarityScoreê°€ ì—†ìœ¼ë©´ chunk.score ì‚¬ìš©
                        if not source.get("similarityScore"):
                            source["similarityScore"] = float(chunk.score)
                        # refinedSnippetì´ ì—†ìœ¼ë©´ chunk.snippet ì‚¬ìš© (ë‹¤ë“¬ì§€ ì•Šì€ ì›ë¬¸)
                        if not source.get("refinedSnippet"):
                            source["refinedSnippet"] = chunk.snippet
                        break
                
                # sourceType ë§¤í•‘ (guideline -> manual, statute -> law)
                if source.get("sourceType") == "guideline":
                    source["sourceType"] = "manual"
                elif source.get("sourceType") == "statute":
                    source["sourceType"] = "law"
                
                # source ì •ë³´ ì—…ë°ì´íŠ¸
                finding["source"] = source
                findings_processed.append(finding)
            
            logger.info(f"[ì›Œí¬í”Œë¡œìš°] findings ì²˜ë¦¬ ì™„ë£Œ: {len(findings_processed)}ê°œ")
        else:
            logger.warning("[ì›Œí¬í”Œë¡œìš°] findingsê°€ ë¹„ì–´ìˆê±°ë‚˜ Noneì…ë‹ˆë‹¤.")
        
        final_output = {
            "classified_type": classification.get("classified_type", "unknown"),
            "risk_score": classification.get("risk_score", 50),
            "summary": summary_report,  # generate_action_guideì—ì„œ ìƒì„±ëœ 4ê°œ ì„¹ì…˜ ë§ˆí¬ë‹¤ìš´
            "criteria": criteria_items,  # RAG ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ (ìƒˆë¡œìš´ êµ¬ì¡°)
            "findings": findings_processed,  # ë²•ì  ìŸì  ë°œê²¬ í•­ëª©
            "action_plan": action_plan,  # steps êµ¬ì¡°
            "scripts": scripts,  # toCompany, toAdvisor
            "related_cases": formatted_related_cases,
            "grounding_chunks": formatted_sources,  # sources í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            "organizations": organizations,  # ì¶”ì²œ ê¸°ê´€ ëª©ë¡
        }
        
        return {
            **state,
            "final_output": final_output,
        }
```

**ì²˜ë¦¬ ë‚´ìš©**:
- `criteria` ìƒì„±: grounding_chunksë¥¼ ê¸°ë°˜ìœ¼ë¡œ usageReason ìƒì„±
- `findings` ì²˜ë¦¬: source ì •ë³´ ë³´ì™„ (fileUrl, similarityScore ë“±)
- `related_cases` í¬ë§·íŒ…
- ìµœì¢… JSON ì¶œë ¥ êµ¬ì„±

#### 3-7. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë©”ì„œë“œ

```2402:2435:backend/core/situation_workflow.py
    async def run(self, initial_state: Dict[str, Any]) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        logger.info("[ì›Œí¬í”Œë¡œìš°] ì‹¤í–‰ ì‹œì‘")
        
        # Stateë¡œ ë³€í™˜
        state: SituationWorkflowState = {
            "situation_text": initial_state.get("situation_text", ""),
            "category_hint": initial_state.get("category_hint"),
            "summary": initial_state.get("summary"),
            "details": initial_state.get("details"),
            "employment_type": initial_state.get("employment_type"),
            "work_period": initial_state.get("work_period"),
            "weekly_hours": initial_state.get("weekly_hours"),
            "is_probation": initial_state.get("is_probation"),
            "social_insurance": initial_state.get("social_insurance"),
            "query_text": None,
            "query_embedding": None,
            "classification": None,
            "filtered_categories": None,
            "grounding_chunks": None,
            "related_cases": None,
            "legal_basis": None,
            "action_plan": None,
            "scripts": None,
            "criteria": None,
            "summary_report": None,
            "final_output": None,
        }
        
        # ê·¸ë˜í”„ ì‹¤í–‰
        final_state = await self.graph.ainvoke(state)
        
        # ìµœì¢… ì¶œë ¥ ë°˜í™˜
        return final_state.get("final_output", {})
```

### 4ë‹¨ê³„: ê²°ê³¼ ë³€í™˜ ë° DB ì €ì¥

**íŒŒì¼**: `backend/api/routes_legal_v2.py` (1266-1659ì¤„)

**ì£¼ìš” ì²˜ë¦¬ ë‚´ìš©**:

1. **ìœ„í—˜ë„ ë ˆë²¨ ë³€í™˜** (1267-1271ì¤„):
   - risk_scoreë¥¼ ê¸°ë°˜ìœ¼ë¡œ risk_level ê³„ì‚° (low/medium/high)

2. **Scripts ë³€í™˜** (1276-1318ì¤„):
   - ì›Œí¬í”Œë¡œìš° ê²°ê³¼ì˜ scriptsë¥¼ EmailTemplateV2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜

3. **RelatedCases ê·¸ë£¹í•‘** (1320-1483ì¤„):
   - grounding_chunksë¥¼ ë¬¸ì„œ ë‹¨ìœ„ë¡œ ê·¸ë£¹í•‘
   - usageReason ë§¤í•‘ ë° ìƒì„±
   - fileUrl ìƒì„±

4. **Sources ë³€í™˜** (1487-1544ì¤„):
   - grounding_chunksë¥¼ sources í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   - snippet ë¶„ì„ ë° fileUrl ìƒì„±

5. **DB ì €ì¥** (1546-1594ì¤„):
   - `storage_service.save_situation_analysis()` í˜¸ì¶œ
   - ë¶„ì„ ê²°ê³¼ë¥¼ JSONBë¡œ ì €ì¥
   - ì‹¤íŒ¨í•´ë„ ì‘ë‹µì€ ì •ìƒ ë°˜í™˜

6. **ìµœì¢… ì‘ë‹µ ìƒì„±** (1634-1659ì¤„):
   - v2 ìŠ¤í™ì— ë§ì¶° ì‘ë‹µ êµ¬ì„±
   - id, riskScore, riskLevel, tags, summary, findings, relatedCases, scripts, organizations í¬í•¨

## ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì¡°

```
prepare_query
    â†“
classify_situation
    â†“
filter_rules
    â†“
retrieve_guides
    â†“
generate_all_fields (ë³‘ë ¬ LLM í˜¸ì¶œ)
    â†“
merge_output
    â†“
END
```

## ì£¼ìš” íŠ¹ì§•

### 1. ë³‘ë ¬ ì²˜ë¦¬
- RAG ê²€ìƒ‰: ë²•ë ¹/ê°€ì´ë“œì™€ ì¼€ì´ìŠ¤ ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰
- LLM í˜¸ì¶œ: summary, findings, scripts, organizationsë¥¼ ë³‘ë ¬ë¡œ ìƒì„±

### 2. ë‹¨ê³„ë³„ í•„í„°ë§
- ìƒí™© ë¶„ë¥˜ â†’ ì¹´í…Œê³ ë¦¬ í•„í„°ë§ â†’ RAG ê²€ìƒ‰
- ë¶ˆí•„ìš”í•œ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œë¡œ ì •í™•ë„ í–¥ìƒ

### 3. ì—ëŸ¬ ì²˜ë¦¬
- ê° ë‹¨ê³„ì—ì„œ ì˜ˆì™¸ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
- ì›Œí¬í”Œë¡œìš° ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜

### 4. ë°ì´í„° ë³€í™˜
- grounding_chunks â†’ criteria (usageReason ìë™ ìƒì„±)
- grounding_chunks â†’ relatedCases (ë¬¸ì„œ ë‹¨ìœ„ ê·¸ë£¹í•‘)
- findings source ì •ë³´ ë³´ì™„

## ì„±ëŠ¥ ìµœì í™”

1. **ë³‘ë ¬ LLM í˜¸ì¶œ**: 4ê°œ í•„ë“œë¥¼ ë™ì‹œì— ìƒì„±í•˜ì—¬ ì´ ì†Œìš” ì‹œê°„ ë‹¨ì¶•
2. **ì¹´í…Œê³ ë¦¬ í•„í„°ë§**: ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œë¡œ RAG ê²€ìƒ‰ ì†ë„ í–¥ìƒ
3. **ì„ë² ë”© ìºì‹±**: ë™ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ì¬ì‚¬ìš©

## ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥

**í…Œì´ë¸”**: `situation_analyses`

**ì €ì¥ í•„ë“œ**:
- `situation`: ì‚¬ìš©ì ì…ë ¥ ìƒí™© í…ìŠ¤íŠ¸
- `category`: ì¹´í…Œê³ ë¦¬
- `employment_type`, `work_period`, `company_size`, `has_written_contract`, `social_insurance`: ë©”íƒ€ ì •ë³´
- `risk_score`, `risk_level`: ìœ„í—˜ë„ ì •ë³´
- `analysis`: ì „ì²´ ë¶„ì„ ê²°ê³¼ (JSONB)
- `related_cases`: ê´€ë ¨ ì‚¬ë¡€ (JSONB)
- `user_id`: ì‚¬ìš©ì ID

## ë¡œê¹…

ê° ë‹¨ê³„ì—ì„œ ìƒì„¸í•œ ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤:
- ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘/ì™„ë£Œ
- ê° ë…¸ë“œ ì‹¤í–‰ ì‹œì‘/ì™„ë£Œ
- RAG ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
- LLM í˜¸ì¶œ ì†Œìš” ì‹œê°„
- ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ì •ë³´

## ì°¸ê³  íŒŒì¼

- **API ì—”ë“œí¬ì¸íŠ¸**: `backend/api/routes_legal_v2.py`
- **ì„œë¹„ìŠ¤ ë ˆì´ì–´**: `backend/core/legal_rag_service.py`
- **ì›Œí¬í”Œë¡œìš°**: `backend/core/situation_workflow.py`
- **í”„ë¡¬í”„íŠ¸**: `backend/core/prompts.py`
- **ë²¡í„° ìŠ¤í† ì–´**: `backend/core/supabase_vector_store.py`
- **ìŠ¤í† ë¦¬ì§€**: `backend/core/contract_storage.py`

