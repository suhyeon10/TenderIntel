"""
ë°°ì¹˜ ì¸ìž… ìŠ¤í¬ë¦½íŠ¸
í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ ìžë™ìœ¼ë¡œ RAGì— ë°˜ì˜

ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:
raw/ â†’ processed/ â†’ indexed/
"""

import os
import sys
import argparse
import json
import shutil
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.orchestrator_v2 import Orchestrator
from core.supabase_vector_store import SupabaseVectorStore
from core.legal_chunker import LegalChunker, extract_doc_type_from_path
from core.document_processor_v2 import DocumentProcessor
from core.generator_v2 import LLMGenerator


class BatchIngester:
    """ë°°ì¹˜ ì¸ìž… ì²˜ë¦¬ê¸°"""
    
    def __init__(self, base_data_dir: str = None):
        self.orchestrator = Orchestrator()
        self.store = SupabaseVectorStore()
        self.results: List[Dict[str, Any]] = []
        
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
        if base_data_dir is None:
            base_data_dir = Path(__file__).parent.parent / "data"
        self.base_data_dir = Path(base_data_dir)
        
        # ë‹¨ìˆœ êµ¬ì¡°: processed/, indexed/ (ì„ íƒì‚¬í•­)
        self.processed_dir = self.base_data_dir / "processed"
        self.indexed_dir = self.base_data_dir / "indexed"
        self.temp_dir = self.base_data_dir / "temp"
        
        # ë””ë ‰í† ë¦¬ ìƒì„± (í•„ìš”ì‹œ)
        for dir_path in [self.processed_dir, self.indexed_dir, self.temp_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # indexed í•˜ìœ„ ë””ë ‰í† ë¦¬ ìƒì„±
        (self.indexed_dir / "reports").mkdir(exist_ok=True)
        (self.indexed_dir / "exports").mkdir(exist_ok=True)
    
    def scan_folder(self, folder_path: str, extensions: List[str] = None) -> List[Path]:
        """
        í´ë” ìŠ¤ìº”í•˜ì—¬ íŒŒì¼ ëª©ë¡ ë°˜í™˜
        
        Args:
            folder_path: ìŠ¤ìº”í•  í´ë” ê²½ë¡œ
            extensions: í—ˆìš©í•  íŒŒì¼ í™•ìž¥ìž (ê¸°ë³¸: ['.pdf', '.txt', '.hwp', '.hwpx'])
        
        Returns:
            íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if extensions is None:
            extensions = ['.pdf', '.txt', '.hwp', '.hwpx', '.html', '.htm', '.csv']
        
        folder = Path(folder_path)
        if not folder.exists():
            raise FileNotFoundError(f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
        
        files = []
        # íŠ¹ìˆ˜ë¬¸ìžê°€ ìžˆëŠ” íŒŒì¼ëª…ë„ ì°¾ê¸° ìœ„í•´ ëª¨ë“  íŒŒì¼ì„ ìŠ¤ìº”í•œ í›„ í™•ìž¥ìžë¡œ í•„í„°ë§
        for file_path in folder.rglob("*"):
            if file_path.is_file():
                # README.md ë“± ì œì™¸
                if file_path.name.lower() in ['readme.md', '.gitkeep']:
                    continue
                # í™•ìž¥ìž í™•ì¸ (ëŒ€ì†Œë¬¸ìž ë¬´ì‹œ)
                if file_path.suffix.lower() in [ext.lower() for ext in extensions]:
                    files.append(file_path)
        
        return sorted(files)
    
    def extract_meta_from_filename(self, file_path: Path) -> Dict[str, Any]:
        """
        íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "ë‚˜ë¼ìž¥í„°_2024-001_ì›¹ì‚¬ì´íŠ¸êµ¬ì¶•.pdf" 
          â†’ source=ë‚˜ë¼ìž¥í„°, external_id=2024-001, title=ì›¹ì‚¬ì´íŠ¸êµ¬ì¶•
        - "ìž…ì°°_ë‚˜ë¼ìž¥í„°_2024-001_ì›¹ì‚¬ì´íŠ¸êµ¬ì¶•.pdf"
          â†’ type=ìž…ì°°, source=ë‚˜ë¼ìž¥í„°, external_id=2024-001, title=ì›¹ì‚¬ì´íŠ¸êµ¬ì¶•
        - "ë‚™ì°°_ë‚˜ë¼ìž¥í„°_2024-001_ë‚™ì°°ìžì •ë³´.pdf"
          â†’ type=ë‚™ì°°, source=ë‚˜ë¼ìž¥í„°, external_id=2024-001, title=ë‚™ì°°ìžì •ë³´
        """
        filename = file_path.stem  # í™•ìž¥ìž ì œê±°
        
        # íŒŒì¼ëª… íŒ¨í„´ íŒŒì‹± (ì„ íƒì‚¬í•­)
        # ê¸°ë³¸ê°’ ì„¤ì •
        meta = {
            "type": "ìž…ì°°",  # ê¸°ë³¸ê°’: ìž…ì°° ê³µê³ 
            "source": "batch_upload",
            "external_id": filename,
            "title": filename,
            "agency": None,
            "budget_min": None,
            "budget_max": None,
            "start_date": None,
            "end_date": None,
        }
        
        # íŒŒì¼ëª…ì—ì„œ íƒ€ìž… ì¶”ì¶œ (ìž…ì°°/ë‚™ì°°)
        filename_lower = filename.lower()
        if filename_lower.startswith("ìž…ì°°_"):
            meta["type"] = "ìž…ì°°"
            filename = filename[3:]  # "ìž…ì°°_" ì œê±°
        elif filename_lower.startswith("ë‚™ì°°_"):
            meta["type"] = "ë‚™ì°°"
            filename = filename[3:]  # "ë‚™ì°°_" ì œê±°
        elif "ë‚™ì°°" in filename_lower or "winner" in filename_lower or "award" in filename_lower:
            meta["type"] = "ë‚™ì°°"
        
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ ì‹œë„
        parts = filename.split('_')
        if len(parts) >= 2:
            meta["source"] = parts[0]
            meta["external_id"] = parts[1] if len(parts) > 1 else filename
            meta["title"] = '_'.join(parts[2:]) if len(parts) > 2 else parts[1]
        
        return meta
    
    def process_file(
        self,
        file_path: Path,
        meta: Dict[str, Any] = None,
        verbose: bool = True,
        default_type: str = None,
        mode: str = "announcements"
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            meta: ë©”íƒ€ë°ì´í„° (ì—†ìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ)
            verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€
            default_type: ê¸°ë³¸ ë¬¸ì„œ íƒ€ìž… ("ìž…ì°°" ë˜ëŠ” "ë‚™ì°°", Noneì´ë©´ ìžë™ ê°ì§€)
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        if meta is None:
            meta = self.extract_meta_from_filename(file_path)
        
        # default_typeì´ ìžˆìœ¼ë©´ íƒ€ìž… ê°•ì œ ì„¤ì •
        if default_type and default_type in ["ìž…ì°°", "ë‚™ì°°"]:
            meta["type"] = default_type
        
        result = {
            "file": str(file_path),
            "status": "pending",
            "announcement_id": None,
            "legal_document_id": None,
            "error": None,
            "started_at": datetime.now().isoformat(),
        }
        
        try:
            if verbose:
                print(f"[ì²˜ë¦¬ ì¤‘] {file_path.name} (ëª¨ë“œ: {mode})")
            
            # Legal ëª¨ë“œ ì²˜ë¦¬
            if mode == "legal":
                return self._process_legal_file(file_path, meta, verbose)
            
            # Announcements ëª¨ë“œ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
            # íŒŒì¼ íƒ€ìž… ê²°ì •
            suffix = file_path.suffix.lower()
            if suffix == ".pdf":
                file_type = "pdf"
            elif suffix in [".hwp", ".hwpx"]:
                file_type = "hwp"
            elif suffix == ".txt":
                file_type = "text"
            elif suffix in [".html", ".htm"]:
                file_type = "html"
            elif suffix == ".csv":
                # CSVëŠ” íŠ¹ë³„ ì²˜ë¦¬ (ì—¬ëŸ¬ ê³µê³ ë¥¼ í•œ íŒŒì¼ì— í¬í•¨)
                return self.process_csv_file(file_path, verbose=verbose)
            else:
                file_type = None  # ìžë™ ê°ì§€
            
            # 1. ì›ë³¸ íŒŒì¼ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì¶”ì¶œ)
            process_result = self.orchestrator.processor.process_file(
                file_path=str(file_path),
                file_type=file_type
            )
            
            # process_fileì€ (text, chunks) íŠœí”Œ ë°˜í™˜
            if isinstance(process_result, tuple):
                text, chunks = process_result
            else:
                # í˜¸í™˜ì„±ì„ ìœ„í•´
                text = process_result
                chunks = []
            
            # 2. processed/ í´ë”ì— ì €ìž¥ (í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„°) - ì„ íƒì‚¬í•­
            processed_file = None
            if self.processed_dir.exists():
                processed_file = self._save_processed_file(
                    file_path=file_path,
                    text=text,
                    meta=meta
                )
            
            # 3. ë²¡í„° ì¸ë±ì‹± (RAG íŒŒì´í”„ë¼ì¸)
            announcement_id = self.orchestrator.process_announcement(meta, text)
            
            # 4. ì²­í¬ ìž„ë² ë”© ì €ìž¥
            chunk_texts = [chunk.content for chunk in chunks]
            embeddings = self.orchestrator.generator.embed(chunk_texts)
            
            chunk_payload = [
                {
                    "chunk_index": chunk.index,
                    "content": chunk.content,
                    "embedding": embeddings[i],
                    "metadata": chunk.metadata
                }
                for i, chunk in enumerate(chunks)
            ]
            
            self.store.bulk_upsert_chunks(announcement_id, chunk_payload)
            
            result.update({
                "status": "success",
                "announcement_id": announcement_id,
                "processed_file": str(processed_file) if processed_file else None,
                "chunks_count": len(chunks),
                "completed_at": datetime.now().isoformat(),
            })
            
            if verbose:
                print(f"[ì™„ë£Œ] {file_path.name} â†’ {announcement_id} ({len(chunks)}ê°œ ì²­í¬)")
        
        except Exception as e:
            result.update({
                "status": "failed",
                "error": str(e),
                "completed_at": datetime.now().isoformat(),
            })
            
            if verbose:
                print(f"[ì‹¤íŒ¨] {file_path.name} - {str(e)}")
        
        return result
    
    def process_csv_file(
        self,
        file_path: Path,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """
        CSV íŒŒì¼ ì²˜ë¦¬ (ì—¬ëŸ¬ ê³µê³ ë¥¼ í•œ íŒŒì¼ì— í¬í•¨)
        
        CSV í˜•ì‹:
        - title, source, external_id, agency, budget_min, budget_max, start_date, end_date, file_path
        
        file_path ì»¬ëŸ¼ì´ ìžˆìœ¼ë©´ í•´ë‹¹ íŒŒì¼ì„ ì½ê³ , ì—†ìœ¼ë©´ CSVì˜ ë‹¤ë¥¸ ì»¬ëŸ¼ì„ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
        """
        import csv
        
        result = {
            "file": str(file_path),
            "status": "pending",
            "announcement_ids": [],
            "processed_count": 0,
            "error": None,
            "started_at": datetime.now().isoformat(),
        }
        
        try:
            if verbose:
                print(f"[CSV ì²˜ë¦¬] {file_path.name}")
            
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
            
            if not rows:
                raise ValueError("CSV íŒŒì¼ì´ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.")
            
            if verbose:
                print(f"  ðŸ“‹ {len(rows)}ê°œ ê³µê³  ë°œê²¬")
            
            announcement_ids = []
            
            for i, row in enumerate(rows, 1):
                try:
                    # íƒ€ìž… í™•ì¸ (ìž…ì°°/ë‚™ì°°)
                    row_type = row.get("type", row.get("document_type", "ìž…ì°°")).strip()
                    if row_type not in ["ìž…ì°°", "ë‚™ì°°"]:
                        # íŒŒì¼ëª…ì´ë‚˜ ë‹¤ë¥¸ ì»¬ëŸ¼ì—ì„œ íƒ€ìž… ì¶”ì¶œ ì‹œë„
                        if "ë‚™ì°°" in str(row.get("title", "")).lower() or "winner" in str(row.get("title", "")).lower():
                            row_type = "ë‚™ì°°"
                        else:
                            row_type = "ìž…ì°°"
                    
                    # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                    meta = {
                        "type": row_type,
                        "source": row.get("source", "csv_upload"),
                        "external_id": row.get("external_id", f"{file_path.stem}_{i}"),
                        "title": row.get("title", f"{row_type} {i}"),
                        "agency": row.get("agency"),
                        "budget_min": int(row["budget_min"]) if row.get("budget_min") else None,
                        "budget_max": int(row["budget_max"]) if row.get("budget_max") else None,
                        "start_date": row.get("start_date"),
                        "end_date": row.get("end_date"),
                        # ë‚™ì°°ìž ì •ë³´ (ë‚™ì°°ì¸ ê²½ìš°)
                        "winner_company": row.get("winner_company") if row_type == "ë‚™ì°°" else None,
                        "winner_amount": int(row["winner_amount"]) if row.get("winner_amount") and row_type == "ë‚™ì°°" else None,
                        "winner_team_id": int(row["winner_team_id"]) if row.get("winner_team_id") and row_type == "ë‚™ì°°" else None,
                    }
                    
                    # íŒŒì¼ ê²½ë¡œê°€ ìžˆìœ¼ë©´ í•´ë‹¹ íŒŒì¼ ì²˜ë¦¬
                    if row.get("file_path"):
                        file_path_str = row["file_path"]
                        if not os.path.isabs(file_path_str):
                            # ìƒëŒ€ ê²½ë¡œë©´ CSV íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ í•´ì„
                            file_path_str = str(file_path.parent / file_path_str)
                        
                        if not os.path.exists(file_path_str):
                            if verbose:
                                print(f"  âš ï¸  [{i}] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path_str}")
                            continue
                        
                        # ìž…ì°° ê³µê³  ì²˜ë¦¬
                        if meta["type"] == "ìž…ì°°":
                            announcement_id = self.orchestrator.process_file(
                                file_path=file_path_str,
                                file_type=None,
                                meta=meta
                            )
                            announcement_ids.append(announcement_id)
                            
                            if verbose:
                                print(f"  âœ… [{i}/{len(rows)}] [ìž…ì°°] {meta['title']} â†’ {announcement_id}")
                        
                        # ë‚™ì°°ìž ì •ë³´ ì²˜ë¦¬
                        elif meta["type"] == "ë‚™ì°°":
                            # ë‚™ì°°ìž ì •ë³´ë„ ê³µê³ ë¡œ ì €ìž¥í•˜ë˜, ë©”íƒ€ë°ì´í„°ì— ë‚™ì°° ì •ë³´ í¬í•¨
                            announcement_id = self.orchestrator.process_file(
                                file_path=file_path_str,
                                file_type=None,
                                meta=meta
                            )
                            announcement_ids.append(announcement_id)
                            
                            # ë‚™ì°° ì´ë ¥ ì €ìž¥ (ì„ íƒì‚¬í•­)
                            if meta.get("winner_team_id") or meta.get("winner_company"):
                                self._save_winner_info(
                                    announcement_id=announcement_id,
                                    meta=meta,
                                    verbose=verbose
                                )
                            
                            if verbose:
                                print(f"  âœ… [{i}/{len(rows)}] [ë‚™ì°°] {meta['title']} â†’ {announcement_id}")
                    
                    # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ìžˆìœ¼ë©´ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                    elif row.get("text") or row.get("content"):
                        text = row.get("text") or row.get("content", "")
                        if text.strip():
                            announcement_id = self.orchestrator.process_announcement(meta, text)
                            announcement_ids.append(announcement_id)
                            
                            # ë‚™ì°°ìž ì •ë³´ ì €ìž¥ (ë‚™ì°°ì¸ ê²½ìš°)
                            if meta["type"] == "ë‚™ì°°" and (meta.get("winner_team_id") or meta.get("winner_company")):
                                self._save_winner_info(
                                    announcement_id=announcement_id,
                                    meta=meta,
                                    verbose=verbose
                                )
                            
                            if verbose:
                                print(f"  âœ… [{i}/{len(rows)}] [{meta['type']}] {meta['title']} â†’ {announcement_id}")
                        else:
                            if verbose:
                                print(f"  âš ï¸  [{i}] í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìžˆìŒ")
                    
                    else:
                        if verbose:
                            print(f"  âš ï¸  [{i}] file_path ë˜ëŠ” text ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤")
                
                except Exception as e:
                    if verbose:
                        print(f"  âŒ [{i}] ì˜¤ë¥˜: {str(e)}")
                    continue
            
            result.update({
                "status": "success",
                "announcement_ids": announcement_ids,
                "processed_count": len(announcement_ids),
                "completed_at": datetime.now().isoformat(),
            })
            
            if verbose:
                print(f"[CSV ì™„ë£Œ] {len(announcement_ids)}ê°œ ê³µê³  ì²˜ë¦¬ë¨")
        
        except Exception as e:
            result.update({
                "status": "failed",
                "error": str(e),
                "completed_at": datetime.now().isoformat(),
            })
            
            if verbose:
                print(f"[CSV ì‹¤íŒ¨] {file_path.name} - {str(e)}")
        
        return result
    
    def _process_legal_file(
        self,
        file_path: Path,
        meta: Dict[str, Any] = None,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """
        ë²•ë¥ /ê³„ì•½ ë¬¸ì„œ ì²˜ë¦¬ (legal ëª¨ë“œ)
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            meta: ë©”íƒ€ë°ì´í„° (ì—†ìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ)
            verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        result = {
            "file": str(file_path),
            "status": "pending",
            "legal_document_id": None,
            "error": None,
            "started_at": datetime.now().isoformat(),
        }
        
        try:
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            if meta is None:
                meta = {}
            
            # íŒŒì¼ëª…ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            filename = file_path.stem
            if not meta.get("title"):
                meta["title"] = filename
            
            # íŒŒì¼ ê²½ë¡œì—ì„œ doc_type ì¶”ì¶œ
            file_path_str = str(file_path)
            doc_type = extract_doc_type_from_path(file_path_str)
            meta["doc_type"] = doc_type
            
            # source ì¶”ì¶œ (í´ë” êµ¬ì¡°ì—ì„œ)
            if "laws" in file_path_str.lower() or "ë²•" in file_path_str.lower():
                source = "moel"  # ê³ ìš©ë…¸ë™ë¶€
            elif "standard_contracts" in file_path_str.lower() or "ê³„ì•½" in file_path_str.lower():
                source = "mss"  # ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€
            elif "manuals" in file_path_str.lower() or "ë§¤ë‰´ì–¼" in file_path_str.lower():
                source = "mcst"  # ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€
            else:
                source = "unknown"
            
            meta["source"] = source
            
            # íŒŒì¼ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ì•ˆì „í•˜ê²Œ)
            try:
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                file_path_abs = Path(file_path).resolve()
                base_data_dir_abs = self.base_data_dir.resolve()
                
                # base_data_dirì˜ í•˜ìœ„ ê²½ë¡œì¸ì§€ í™•ì¸
                if str(file_path_abs).startswith(str(base_data_dir_abs)):
                    meta["file_path"] = str(file_path_abs.relative_to(base_data_dir_abs))
                else:
                    # í•˜ìœ„ ê²½ë¡œê°€ ì•„ë‹ˆë©´ íŒŒì¼ëª…ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ ì „ì²´ ê²½ë¡œ ì‚¬ìš©
                    # data/legal/... í˜•íƒœë¡œ ì‹œìž‘í•˜ëŠ”ì§€ í™•ì¸
                    file_path_str = str(file_path)
                    if "data" in file_path_str:
                        # data ì´í›„ì˜ ê²½ë¡œë§Œ ì¶”ì¶œ
                        data_idx = file_path_str.find("data")
                        meta["file_path"] = file_path_str[data_idx:]
                    else:
                        # ê·¸ ì™¸ì—ëŠ” íŒŒì¼ëª…ë§Œ
                        meta["file_path"] = file_path.name
            except Exception as e:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ íŒŒì¼ëª…ë§Œ ì‚¬ìš©
                meta["file_path"] = file_path.name
            
            # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
            processor = DocumentProcessor()
            suffix = file_path.suffix.lower()
            if suffix == ".pdf":
                file_type = "pdf"
            elif suffix in [".hwp", ".hwpx"]:
                file_type = "hwp"
            elif suffix == ".txt":
                file_type = "text"
            elif suffix in [".html", ".htm"]:
                file_type = "html"
            else:
                file_type = None
            
            text, _ = processor.process_file(str(file_path), file_type)
            
            # 2. Legal Chunkerë¡œ ì²­í¬ ìƒì„±
            chunker = LegalChunker(max_chars=1200, overlap=200)
            legal_chunks = chunker.build_legal_chunks(
                text=text,
                source_name=source,
                file_path=meta["file_path"]
            )
            
            if not legal_chunks:
                raise Exception("ë²•ë¥  ì²­í¬ ìƒì„± ì‹¤íŒ¨")
            
            # 3. ë²•ë¥  ë¬¸ì„œ ì €ìž¥
            legal_document_id = self.store.upsert_legal_document(meta, text)
            
            # 4. ì²­í¬ ìž„ë² ë”© ìƒì„± ë° ì €ìž¥
            generator = LLMGenerator()
            chunk_texts = [chunk.text for chunk in legal_chunks]
            embeddings = generator.embed(chunk_texts)
            
            chunk_payload = [
                {
                    "section_title": chunk.section_title,
                    "chunk_index": chunk.chunk_index,
                    "text": chunk.text,
                    "embedding": embeddings[i],
                    "meta": {}
                }
                for i, chunk in enumerate(legal_chunks)
            ]
            
            self.store.bulk_upsert_legal_chunks(legal_document_id, chunk_payload)
            
            result.update({
                "status": "success",
                "legal_document_id": legal_document_id,
                "chunks_count": len(legal_chunks),
                "completed_at": datetime.now().isoformat(),
            })
            
            if verbose:
                print(f"[ì™„ë£Œ] {file_path.name} â†’ {legal_document_id} ({len(legal_chunks)}ê°œ ì²­í¬)")
        
        except Exception as e:
            result.update({
                "status": "failed",
                "error": str(e),
                "completed_at": datetime.now().isoformat(),
            })
            
            if verbose:
                print(f"[ì‹¤íŒ¨] {file_path.name} - {str(e)}")
        
        return result
    
    def _save_processed_file(
        self,
        file_path: Path,
        text: str,
        meta: Dict[str, Any]
    ) -> Path:
        """
        ì „ì²˜ë¦¬ëœ íŒŒì¼ì„ processed/ í´ë”ì— ì €ìž¥
        
        Args:
            file_path: ì›ë³¸ íŒŒì¼ ê²½ë¡œ
            text: ì¶”ì¶œëœ í…ìŠ¤íŠ¸
            meta: ë©”íƒ€ë°ì´í„°
        
        Returns:
            ì €ìž¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # ì¶œì²˜ë³„ í´ë” êµ¬ì¡° ìœ ì§€
            source = meta.get("source", "ê¸°íƒ€")
            doc_type = meta.get("type", "ìž…ì°°")
            
            # processed/{source}/{type}/ êµ¬ì¡° ìƒì„±
            processed_source_dir = self.processed_dir / source / doc_type
            processed_source_dir.mkdir(parents=True, exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„± (ì›ë³¸ íŒŒì¼ëª… ê¸°ë°˜)
            filename = file_path.stem + ".json"
            processed_file = processed_source_dir / filename
            
            # JSON í˜•ì‹ìœ¼ë¡œ ì €ìž¥ (í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„°)
            processed_data = {
                "source_file": str(file_path),
                "extracted_at": datetime.now().isoformat(),
                "meta": meta,
                "text": text,
                "text_length": len(text),
            }
            
            with open(processed_file, 'w', encoding='utf-8') as f:
                json.dump(processed_data, f, ensure_ascii=False, indent=2)
            
            return processed_file
        
        except Exception as e:
            print(f"[ê²½ê³ ] processed íŒŒì¼ ì €ìž¥ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def _save_winner_info(
        self,
        announcement_id: str,
        meta: Dict[str, Any],
        verbose: bool = True
    ):
        """
        ë‚™ì°°ìž ì •ë³´ ì €ìž¥ (bidding_history í…Œì´ë¸”ì— ì €ìž¥)
        """
        try:
            from supabase import create_client
            import os
            
            supabase_url = os.getenv("SUPABASE_URL")
            supabase_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
            
            if not supabase_url or not supabase_key:
                if verbose:
                    print(f"  âš ï¸  Supabase ì„¤ì •ì´ ì—†ì–´ ë‚™ì°°ìž ì •ë³´ë¥¼ ì €ìž¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return
            
            supabase = create_client(supabase_url, supabase_key)
            
            # bidding_historyì— ë‚™ì°° ì •ë³´ ì €ìž¥
            winner_data = {
                "announcement_id": announcement_id,
                "is_won": True,
                "actual_amount": meta.get("winner_amount"),
            }
            
            if meta.get("winner_team_id"):
                winner_data["team_id"] = meta["winner_team_id"]
            
            # ê¸°ì¡´ ê³µê³  IDë¡œ ì°¾ê¸° (external_idë¡œ ë§¤ì¹­)
            if meta.get("external_id"):
                # announcements í…Œì´ë¸”ì—ì„œ external_idë¡œ ì°¾ê¸°
                ann_result = supabase.table("announcements")\
                    .select("id")\
                    .eq("external_id", meta["external_id"])\
                    .eq("source", meta.get("source", ""))\
                    .order("version", desc=True)\
                    .limit(1)\
                    .execute()
                
                if ann_result.data and len(ann_result.data) > 0:
                    winner_data["announcement_id"] = ann_result.data[0]["id"]
            
            # ë‚™ì°° ì´ë ¥ ì €ìž¥
            result = supabase.table("bidding_history")\
                .insert(winner_data)\
                .execute()
            
            if verbose:
                print(f"    ðŸ’¾ ë‚™ì°°ìž ì •ë³´ ì €ìž¥ë¨")
        
        except Exception as e:
            if verbose:
                print(f"    âš ï¸  ë‚™ì°°ìž ì •ë³´ ì €ìž¥ ì‹¤íŒ¨: {str(e)}")
    
    def process_folder(
        self,
        folder_path: str,
        extensions: List[str] = None,
        parallel: bool = False,
        max_workers: int = 3,
        verbose: bool = True,
        auto_detect_type: bool = True,
        mode: str = "announcements"
    ) -> Dict[str, Any]:
        """
        í´ë”ì˜ ëª¨ë“  íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬
        
        Args:
            folder_path: í´ë” ê²½ë¡œ
            extensions: í—ˆìš©í•  íŒŒì¼ í™•ìž¥ìž
            parallel: ë³‘ë ¬ ì²˜ë¦¬ ì—¬ë¶€
            max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ìµœëŒ€ ì›Œì»¤ ìˆ˜
            verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€
            auto_detect_type: íŒŒì¼ëª…ì—ì„œ ìž…ì°°/ë‚™ì°° ìžë™ ê°ì§€ (ê¸°ë³¸: True)
        
        Returns:
            ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
        """
        folder = Path(folder_path)
        
        # í•˜ìœ„ í´ë” êµ¬ì¡° í™•ì¸ (bids/winners ë˜ëŠ” ìž…ì°°/ë‚™ì°°)
        bids_folder = folder / "bids"
        winners_folder = folder / "winners"
        bids_folder_kr = folder / "ìž…ì°°"
        winners_folder_kr = folder / "ë‚™ì°°"
        
        # í•˜ìœ„ í´ë”ê°€ ìžˆìœ¼ë©´ ê°ê° ì²˜ë¦¬
        has_bids = bids_folder.exists() or bids_folder_kr.exists()
        has_winners = winners_folder.exists() or winners_folder_kr.exists()
        
        if has_bids or has_winners:
            if verbose:
                print(f"[êµ¬ì¡° ê°ì§€] í•˜ìœ„ í´ë” êµ¬ì¡° ë°œê²¬")
            
            results = {
                "total": 0,
                "success": 0,
                "failed": 0,
                "results": [],
                "bids": {"total": 0, "success": 0, "failed": 0},
                "winners": {"total": 0, "success": 0, "failed": 0}
            }
            
            # ìž…ì°° í´ë” ì²˜ë¦¬
            bids_path = bids_folder if bids_folder.exists() else bids_folder_kr
            if bids_path.exists():
                if verbose:
                    print(f"\n[ìž…ì°° ê³µê³ ] {bids_path} ì²˜ë¦¬ ì¤‘...")
                bids_result = self._process_single_folder(
                    str(bids_path), extensions, parallel, max_workers, verbose, "ìž…ì°°"
                )
                results["bids"] = {
                    "total": bids_result["total"],
                    "success": bids_result["success"],
                    "failed": bids_result["failed"]
                }
                results["total"] += bids_result["total"]
                results["success"] += bids_result["success"]
                results["failed"] += bids_result["failed"]
                results["results"].extend(bids_result["results"])
            
            # ë‚™ì°° í´ë” ì²˜ë¦¬
            winners_path = winners_folder if winners_folder.exists() else winners_folder_kr
            if winners_path.exists():
                if verbose:
                    print(f"\n[ë‚™ì°°ìž ì •ë³´] {winners_path} ì²˜ë¦¬ ì¤‘...")
                winners_result = self._process_single_folder(
                    str(winners_path), extensions, parallel, max_workers, verbose, "ë‚™ì°°"
                )
                results["winners"] = {
                    "total": winners_result["total"],
                    "success": winners_result["success"],
                    "failed": winners_result["failed"]
                }
                results["total"] += winners_result["total"]
                results["success"] += winners_result["success"]
                results["failed"] += winners_result["failed"]
                results["results"].extend(winners_result["results"])
            
            # ê²°ê³¼ ì¶œë ¥
            if verbose:
                print(f"\n{'='*50}")
                print(f"[ì™„ë£Œ] ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
                print(f"   ì „ì²´: {results['total']}ê°œ")
                print(f"   ìž…ì°°: {results['bids']['success']}/{results['bids']['total']}ê°œ ì„±ê³µ")
                print(f"   ë‚™ì°°: {results['winners']['success']}/{results['winners']['total']}ê°œ ì„±ê³µ")
                print(f"   ì‹¤íŒ¨: {results['failed']}ê°œ")
                print(f"{'='*50}")
            
            results["processed_at"] = datetime.now().isoformat()
            return results
        
        # ë‹¨ì¼ í´ë” ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
        return self._process_single_folder(
            folder_path, extensions, parallel, max_workers, verbose, 
            "ìž…ì°°" if not auto_detect_type else None,
            mode=mode
        )
    
    def _process_single_folder(
        self,
        folder_path: str,
        extensions: List[str] = None,
        parallel: bool = False,
        max_workers: int = 3,
        verbose: bool = True,
        default_type: str = None,
        mode: str = "announcements"
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ í´ë” ì²˜ë¦¬ (ë‚´ë¶€ ë©”ì„œë“œ)
        
        Args:
            default_type: ê¸°ë³¸ ë¬¸ì„œ íƒ€ìž… ("ìž…ì°°" ë˜ëŠ” "ë‚™ì°°", Noneì´ë©´ ìžë™ ê°ì§€)
        """
        # íŒŒì¼ ìŠ¤ìº”
        files = self.scan_folder(folder_path, extensions)
        
        if not files:
            if verbose:
                print(f"[ê²½ê³ ] ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
            return {
                "total": 0,
                "success": 0,
                "failed": 0,
                "results": []
            }
        
        if verbose:
            print(f"[ë°œê²¬] íŒŒì¼: {len(files)}ê°œ")
            if default_type:
                print(f"[íƒ€ìž…] {default_type}ë¡œ ì²˜ë¦¬")
            print(f"[ì‹œìž‘] ì²˜ë¦¬ ì‹œìž‘...\n")
        
        # íŒŒì¼ ì²˜ë¦¬
        if parallel:
            # ë³‘ë ¬ ì²˜ë¦¬ (ë©€í‹°í”„ë¡œì„¸ì‹±)
            from concurrent.futures import ThreadPoolExecutor
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                results = list(executor.map(
                    lambda f: self.process_file(f, verbose=verbose, default_type=default_type, mode=mode),
                    files
                ))
        else:
            # ìˆœì°¨ ì²˜ë¦¬
            results = []
            for i, file in enumerate(files, 1):
                if verbose:
                    print(f"[{i}/{len(files)}] ", end="")
                result = self.process_file(file, verbose=verbose, default_type=default_type, mode=mode)
                results.append(result)
        
        # ê²°ê³¼ ì§‘ê³„
        success_count = sum(1 for r in results if r["status"] == "success")
        failed_count = sum(1 for r in results if r["status"] == "failed")
        
        summary = {
            "total": len(files),
            "success": success_count,
            "failed": failed_count,
            "results": results,
            "processed_at": datetime.now().isoformat(),
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*50}")
        print(f"[ì™„ë£Œ] ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
        print(f"   ì „ì²´: {summary['total']}ê°œ")
        print(f"   ì„±ê³µ: {summary['success']}ê°œ")
        print(f"   ì‹¤íŒ¨: {summary['failed']}ê°œ")
        print(f"{'='*50}")
        
        return summary
    
    def save_report(self, summary: Dict[str, Any], output_path: str = None):
        """
        ì²˜ë¦¬ ê²°ê³¼ ë¦¬í¬íŠ¸ ì €ìž¥
        
        Args:
            summary: ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
            output_path: ë¦¬í¬íŠ¸ ì €ìž¥ ê²½ë¡œ (ì—†ìœ¼ë©´ ìžë™ ìƒì„±)
        """
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = self.indexed_dir / "reports" / f"report_{timestamp}.json"
        else:
            output_path = Path(output_path)
        
        # ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # JSON ì €ìž¥
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"[ì €ìž¥] ë¦¬í¬íŠ¸: {output_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ê³µê³ /ë²•ë¥  ë¬¸ì„œ ë°°ì¹˜ ì¸ìž… ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "folder",
        type=str,
        help="ì²˜ë¦¬í•  í´ë” ê²½ë¡œ"
    )
    parser.add_argument(
        "--mode",
        type=str,
        choices=["announcements", "legal"],
        default="announcements",
        help="ì²˜ë¦¬ ëª¨ë“œ: announcements (ê³µê³ ) ë˜ëŠ” legal (ë²•ë¥ /ê³„ì•½) (ê¸°ë³¸: announcements)"
    )
    parser.add_argument(
        "--extensions",
        type=str,
        nargs="+",
        default=[".pdf", ".txt", ".html", ".htm", ".csv"],
        help="ì²˜ë¦¬í•  íŒŒì¼ í™•ìž¥ìž (ê¸°ë³¸: .pdf .txt .html .htm .csv)"
    )
    parser.add_argument(
        "--parallel",
        action="store_true",
        help="ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”"
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=3,
        help="ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ìµœëŒ€ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 3)"
    )
    parser.add_argument(
        "--report",
        type=str,
        help="ë¦¬í¬íŠ¸ ì €ìž¥ ê²½ë¡œ (ì„ íƒ)"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="ì§„í–‰ ìƒí™© ì¶œë ¥ ì•ˆ í•¨"
    )
    
    args = parser.parse_args()
    
    # ë°°ì¹˜ ì²˜ë¦¬ê¸° ìƒì„±
    ingester = BatchIngester()
    
    # í´ë” ì²˜ë¦¬
    summary = ingester.process_folder(
        folder_path=args.folder,
        extensions=args.extensions,
        parallel=args.parallel,
        max_workers=args.max_workers,
        verbose=not args.quiet,
        mode=args.mode
    )
    
    # ë¦¬í¬íŠ¸ ì €ìž¥
    if args.report or not args.quiet:
        ingester.save_report(summary, args.report)
    
    # ì‹¤íŒ¨í•œ íŒŒì¼ì´ ìžˆìœ¼ë©´ ì¢…ë£Œ ì½”ë“œ 1
    if summary["failed"] > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()

