"""
ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
RAG ì‹œìŠ¤í…œì˜ ê° ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ ì¸¡ì •
"""

import asyncio
import time
import statistics
import json
from datetime import datetime
from typing import List, Dict, Any
from pathlib import Path
import sys
import warnings

# langchain-communityì˜ Ollama Deprecated ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=DeprecationWarning, module="langchain")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.generator_v2 import LLMGenerator
from core.legal_rag_service import LegalRAGService
from core.supabase_vector_store import SupabaseVectorStore
from core.document_processor_v2 import DocumentProcessor
from config import settings

# ìƒí™©ë¶„ì„ ì›Œí¬í”Œë¡œìš° (ì„ íƒì )
try:
    from core.situation_workflow import SituationWorkflow
    SITUATION_WORKFLOW_AVAILABLE = True
except ImportError:
    SITUATION_WORKFLOW_AVAILABLE = False


class PerformanceTester:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, save_results: bool = True, save_dir: str = None):
        self.generator = LLMGenerator()
        self.legal_service = LegalRAGService(embedding_cache_size=100)
        self.vector_store = SupabaseVectorStore()
        self.processor = DocumentProcessor()
        self.results: Dict[str, List[float]] = {}
        self.save_results = save_results
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if save_dir is None:
            save_dir = Path(__file__).parent.parent / "data" / "indexed" / "reports" / "performance"
        else:
            save_dir = Path(save_dir)
        
        self.save_dir = save_dir
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.result_file = self.save_dir / f"performance_test_{self.timestamp}.json"
        
        # ì „ì²´ ê²°ê³¼ ë°ì´í„°
        self.all_results = {
            "timestamp": self.timestamp,
            "datetime": datetime.now().isoformat(),
            "config": {
                "embedding_model": settings.local_embedding_model,
                "llm_model": settings.ollama_model,
                "vector_db": "Supabase" if settings.supabase_url else "ChromaDB",
            },
            "results": {}
        }
    
    def print_header(self, title: str):
        """í—¤ë” ì¶œë ¥"""
        print("\n" + "=" * 60)
        print(f"  {title}")
        print("=" * 60)
    
    def print_result(self, test_name: str, times: List[float], unit: str = "ì´ˆ"):
        """ê²°ê³¼ ì¶œë ¥"""
        if not times:
            print(f"âŒ {test_name}: ì¸¡ì • ì‹¤íŒ¨")
            return
        
        avg = statistics.mean(times)
        median = statistics.median(times)
        min_time = min(times)
        max_time = max(times)
        std_dev = statistics.stdev(times) if len(times) > 1 else 0
        
        print(f"\nğŸ“Š {test_name}")
        print(f"   í‰ê· : {avg:.3f} {unit}")
        print(f"   ì¤‘ì•™ê°’: {median:.3f} {unit}")
        print(f"   ìµœì†Œ: {min_time:.3f} {unit}")
        print(f"   ìµœëŒ€: {max_time:.3f} {unit}")
        print(f"   í‘œì¤€í¸ì°¨: {std_dev:.3f} {unit}")
        print(f"   ì¸¡ì • íšŸìˆ˜: {len(times)}íšŒ")
        
        self.results[test_name] = times
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
        if self.save_results:
            self._save_result(test_name, times)
    
    async def test_embedding_single(self, iterations: int = 10) -> List[float]:
        """ë‹¨ì¼ ì„ë² ë”© ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.print_header("1. ë‹¨ì¼ ì„ë² ë”© ìƒì„± ì„±ëŠ¥")
        
        test_texts = [
            "ê·¼ë¡œê³„ì•½ì„œì˜ ìˆ˜ìŠµ ê¸°ê°„ì€ ìµœëŒ€ 3ê°œì›”ì„ ì´ˆê³¼í•  ìˆ˜ ì—†ë‹¤.",
            "ì„ê¸ˆì€ ë§¤ì›” ë§ì¼ì— ì§€ê¸‰í•˜ë©°, ì§€ê¸‰ì¼ì´ íœ´ì¼ì¸ ê²½ìš° ê·¸ ì „ì¼ë¡œ ì§€ê¸‰í•œë‹¤.",
            "ê·¼ë¡œìëŠ” ì •ë‹¹í•œ ì‚¬ìœ  ì—†ì´ ê·¼ë¡œë¥¼ ì œê³µí•˜ì§€ ì•Šì„ ìˆ˜ ì—†ë‹¤.",
            "ì‚¬ìš©ìëŠ” ê·¼ë¡œìì˜ ì•ˆì „ê³¼ ê±´ê°•ì„ ë³´í˜¸í•  ì˜ë¬´ê°€ ìˆë‹¤.",
            "ê·¼ë¡œì‹œê°„ì€ 1ì£¼ 40ì‹œê°„ì„ ì´ˆê³¼í•  ìˆ˜ ì—†ë‹¤.",
        ]
        
        times = []
        for i in range(iterations):
            text = test_texts[i % len(test_texts)]
            start = time.time()
            try:
                embedding = await asyncio.to_thread(self.generator.embed_one, text)
                elapsed = time.time() - start
                times.append(elapsed)
                print(f"   [{i+1}/{iterations}] {elapsed:.3f}ì´ˆ - '{text[:30]}...'")
            except Exception as e:
                print(f"   âŒ [{i+1}/{iterations}] ì‹¤íŒ¨: {str(e)}")
        
        return times
    
    async def test_embedding_batch(self, batch_sizes: List[int] = [1, 5, 10, 20]) -> Dict[int, List[float]]:
        """ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.print_header("2. ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì„±ëŠ¥")
        
        test_texts = [
            f"ê·¼ë¡œê³„ì•½ì„œ ì¡°í•­ {i}: ê·¼ë¡œìëŠ” ì •ë‹¹í•œ ì‚¬ìœ  ì—†ì´ ê·¼ë¡œë¥¼ ì œê³µí•˜ì§€ ì•Šì„ ìˆ˜ ì—†ë‹¤."
            for i in range(50)
        ]
        
        results = {}
        for batch_size in batch_sizes:
            print(f"\n   ë°°ì¹˜ í¬ê¸°: {batch_size}")
            times = []
            for i in range(3):  # ê° ë°°ì¹˜ í¬ê¸°ë‹¹ 3íšŒ ì¸¡ì •
                batch = test_texts[:batch_size]
                start = time.time()
                try:
                    embeddings = await asyncio.to_thread(self.generator.embed, batch)
                    elapsed = time.time() - start
                    times.append(elapsed)
                    avg_per_item = elapsed / batch_size
                    print(f"      [{i+1}/3] {elapsed:.3f}ì´ˆ (í•­ëª©ë‹¹ {avg_per_item:.3f}ì´ˆ)")
                except Exception as e:
                    print(f"      âŒ [{i+1}/3] ì‹¤íŒ¨: {str(e)}")
            
            if times:
                avg = statistics.mean(times)
                avg_per_item = avg / batch_size
                print(f"      í‰ê· : {avg:.3f}ì´ˆ (í•­ëª©ë‹¹ {avg_per_item:.3f}ì´ˆ)")
                results[batch_size] = times
        
        return results
    
    async def test_embedding_cache(self, iterations: int = 20) -> Dict[str, List[float]]:
        """ì„ë² ë”© ìºì‹œ íš¨ê³¼ í…ŒìŠ¤íŠ¸"""
        self.print_header("3. ì„ë² ë”© ìºì‹œ íš¨ê³¼")
        
        test_text = "ê·¼ë¡œê³„ì•½ì„œì˜ ìˆ˜ìŠµ ê¸°ê°„ì€ ìµœëŒ€ 3ê°œì›”ì„ ì´ˆê³¼í•  ìˆ˜ ì—†ë‹¤."
        
        # ìºì‹œ ì—†ì´ (ì²« ì‹¤í–‰)
        print("\n   ìºì‹œ ì—†ì´ (ì²« ì‹¤í–‰):")
        first_times = []
        for i in range(5):
            start = time.time()
            try:
                embedding = await asyncio.to_thread(self.generator.embed_one, test_text)
                elapsed = time.time() - start
                first_times.append(elapsed)
                print(f"      [{i+1}/5] {elapsed:.3f}ì´ˆ")
            except Exception as e:
                print(f"      âŒ [{i+1}/5] ì‹¤íŒ¨: {str(e)}")
        
        # ìºì‹œ ìˆìŒ (ì¬ì‚¬ìš©)
        print("\n   ìºì‹œ ìˆìŒ (ì¬ì‚¬ìš©):")
        cached_times = []
        for i in range(iterations):
            start = time.time()
            try:
                # LegalRAGServiceì˜ ìºì‹œë¥¼ ì‚¬ìš©
                embedding = await self.legal_service._get_embedding(test_text)
                elapsed = time.time() - start
                cached_times.append(elapsed)
                if i < 5:
                    print(f"      [{i+1}/{iterations}] {elapsed:.3f}ì´ˆ")
            except Exception as e:
                print(f"      âŒ [{i+1}/{iterations}] ì‹¤íŒ¨: {str(e)}")
        
        return {
            "ìºì‹œ ì—†ìŒ": first_times,
            "ìºì‹œ ìˆìŒ": cached_times
        }
    
    async def test_vector_search(self, iterations: int = 10) -> List[float]:
        """ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.print_header("4. ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥")
        
        queries = [
            "ìˆ˜ìŠµ ê¸°ê°„ í•´ê³  ì¡°ê±´",
            "ì„ê¸ˆ ì§€ê¸‰ ì‹œê¸°",
            "ê·¼ë¡œì‹œê°„ ì œí•œ",
            "íœ´ê°€ ë° íœ´ì§",
            "í•´ê³  ì‚¬ìœ  ë° ì ˆì°¨",
        ]
        
        times = []
        for i in range(iterations):
            query = queries[i % len(queries)]
            start = time.time()
            try:
                chunks = await self.legal_service._search_legal_chunks(query=query, top_k=10)
                elapsed = time.time() - start
                times.append(elapsed)
                print(f"   [{i+1}/{iterations}] {elapsed:.3f}ì´ˆ - '{query}' (ê²°ê³¼: {len(chunks)}ê°œ)")
            except Exception as e:
                print(f"   âŒ [{i+1}/{iterations}] ì‹¤íŒ¨: {str(e)}")
        
        return times
    
    async def test_llm_response(self, iterations: int = 5) -> List[float]:
        """LLM ì‘ë‹µ ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.print_header("5. LLM ì‘ë‹µ ìƒì„± ì„±ëŠ¥")
        
        queries = [
            "ìˆ˜ìŠµ ê¸°ê°„ í•´ê³  ì¡°ê±´ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì„ê¸ˆ ì§€ê¸‰ ì‹œê¸°ëŠ” ì–¸ì œì¸ê°€ìš”?",
            "ê·¼ë¡œì‹œê°„ ì œí•œì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        ]
        
        # LLM ì´ˆê¸°í™”
        from config import settings
        times = []
        
        for i in range(iterations):
            query = queries[i % len(queries)]
            start = time.time()
            try:
                if settings.use_groq:
                    # Groq ì‚¬ìš©
                    from llm_api import ask_groq_with_messages
                    messages = [
                        {"role": "system", "content": "ë„ˆëŠ” ìœ ëŠ¥í•œ ë²•ë¥  AIì•¼. í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì— ê°„ë‹¨íˆ ë‹µë³€í•˜ì„¸ìš”: {query}"}
                    ]
                    response_text = await asyncio.to_thread(
                        ask_groq_with_messages,
                        messages=messages,
                        temperature=settings.llm_temperature,
                        model=settings.groq_model
                    )
                elif settings.use_ollama:
                    # Ollama ì‚¬ìš© - langchain-community ìš°ì„  ì‚¬ìš© (think íŒŒë¼ë¯¸í„° ì—ëŸ¬ ë°©ì§€)
                    try:
                        from langchain_community.llms import Ollama
                        llm = Ollama(
                            base_url=settings.ollama_base_url,
                            model=settings.ollama_model
                        )
                    except ImportError:
                        # ëŒ€ì•ˆ: langchain-ollama ì‚¬ìš© (think íŒŒë¼ë¯¸í„° ì—ëŸ¬ ê°€ëŠ¥)
                        try:
                            from langchain_ollama import OllamaLLM
                            llm = OllamaLLM(
                                base_url=settings.ollama_base_url,
                                model=settings.ollama_model
                            )
                        except Exception as e:
                            if "think" in str(e).lower():
                                print("   [ê²½ê³ ] langchain-ollamaì—ì„œ think íŒŒë¼ë¯¸í„° ì—ëŸ¬ ë°œìƒ. langchain-communityë¡œ ì¬ì‹œë„...")
                                from langchain_community.llms import Ollama
                                llm = Ollama(
                                    base_url=settings.ollama_base_url,
                                    model=settings.ollama_model
                                )
                            else:
                                raise
                    
                    prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì— ê°„ë‹¨íˆ ë‹µë³€í•˜ì„¸ìš”: {query}"
                    response_text = await asyncio.to_thread(llm.invoke, prompt)
                else:
                    print(f"   âŒ [{i+1}/{iterations}] LLMì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    continue
                
                elapsed = time.time() - start
                times.append(elapsed)
                response_preview = response_text[:50] if isinstance(response_text, str) else str(response_text)[:50]
                print(f"   [{i+1}/{iterations}] {elapsed:.3f}ì´ˆ - '{query}'")
                print(f"      ì‘ë‹µ: {response_preview}...")
            except Exception as e:
                print(f"   âŒ [{i+1}/{iterations}] ì‹¤íŒ¨: {str(e)}")
        
        return times
    
    async def test_dual_rag_search(self, iterations: int = 5) -> List[float]:
        """Dual RAG ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.print_header("6. Dual RAG ê²€ìƒ‰ ì„±ëŠ¥")
        
        query = "ìˆ˜ìŠµ ê¸°ê°„ í•´ê³  ì¡°ê±´"
        doc_id = None  # í…ŒìŠ¤íŠ¸ìš© doc_id (ì‹¤ì œë¡œëŠ” ì¡´ì¬í•˜ëŠ” doc_id ì‚¬ìš©)
        
        times = []
        for i in range(iterations):
            start = time.time()
            try:
                # ê³„ì•½ì„œ ì²­í¬ ê²€ìƒ‰ê³¼ ë²•ë ¹ ì²­í¬ ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
                query_embedding = await self.legal_service._get_embedding(query)
                
                # ë³‘ë ¬ ê²€ìƒ‰
                if doc_id:
                    contract_task = self.legal_service._search_contract_chunks(
                        doc_id=doc_id,
                        query=query,
                        top_k=5
                    )
                else:
                    # doc_idê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ì½”ë£¨í‹´
                    async def empty_contract_chunks():
                        return []
                    contract_task = empty_contract_chunks()
                
                legal_task = self.legal_service._search_legal_chunks(query=query, top_k=8)
                
                contract_chunks, legal_chunks = await asyncio.gather(
                    contract_task,
                    legal_task,
                    return_exceptions=True
                )
                
                elapsed = time.time() - start
                times.append(elapsed)
                
                # None ì²´í¬ ì¶”ê°€
                if isinstance(contract_chunks, Exception):
                    contract_count = 0
                elif contract_chunks is None:
                    contract_count = 0
                else:
                    contract_count = len(contract_chunks)
                
                if isinstance(legal_chunks, Exception):
                    legal_count = 0
                elif legal_chunks is None:
                    legal_count = 0
                else:
                    legal_count = len(legal_chunks)
                
                print(f"   [{i+1}/{iterations}] {elapsed:.3f}ì´ˆ - ê³„ì•½ì„œ: {contract_count}ê°œ, ë²•ë ¹: {legal_count}ê°œ")
            except Exception as e:
                print(f"   âŒ [{i+1}/{iterations}] ì‹¤íŒ¨: {str(e)}")
        
        return times
    
    async def test_contract_analysis_pipeline(self, test_text: str = None) -> Dict[str, float]:
        """ì „ì²´ ê³„ì•½ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.print_header("7. ì „ì²´ ê³„ì•½ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸")
        
        if not test_text:
            test_text = """
            ì œ1ì¡° (ê·¼ë¡œê¸°ê°„)
            ë³¸ ê³„ì•½ì˜ ê·¼ë¡œê¸°ê°„ì€ 2024ë…„ 1ì›” 1ì¼ë¶€í„° 2024ë…„ 12ì›” 31ì¼ê¹Œì§€ë¡œ í•œë‹¤.
            
            ì œ2ì¡° (ìˆ˜ìŠµê¸°ê°„)
            ê·¼ë¡œìëŠ” ìˆ˜ìŠµê¸°ê°„ 6ê°œì›”ì„ ê±°ì³ì•¼ í•˜ë©°, ìˆ˜ìŠµê¸°ê°„ ì¤‘ì—ëŠ” ì •ë‹¹í•œ ì‚¬ìœ  ì—†ì´ í•´ê³ í•  ìˆ˜ ìˆë‹¤.
            
            ì œ3ì¡° (ê·¼ë¡œì‹œê°„)
            ê·¼ë¡œì‹œê°„ì€ 1ì£¼ 50ì‹œê°„ì„ ì´ˆê³¼í•  ìˆ˜ ì—†ìœ¼ë©°, íœ´ê²Œì‹œê°„ì€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.
            
            ì œ4ì¡° (ì„ê¸ˆ)
            ì„ê¸ˆì€ ë§¤ì›” ë§ì¼ì— ì§€ê¸‰í•˜ë©°, ì§€ê¸‰ì¼ì´ íœ´ì¼ì¸ ê²½ìš° ê·¸ ì „ì¼ë¡œ ì§€ê¸‰í•œë‹¤.
            """
        
        pipeline_times = {}
        
        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì´ë¯¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì‚¬ìš©)
        print("\n   1ë‹¨ê³„: í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìŠ¤í‚µ - ì´ë¯¸ ì¶”ì¶œë¨)")
        
        # 2. ì²­í‚¹
        print("   2ë‹¨ê³„: ì²­í‚¹")
        start = time.time()
        try:
            chunks = self.processor.to_contract_chunks(test_text)
            elapsed = time.time() - start
            pipeline_times["ì²­í‚¹"] = elapsed
            print(f"      ì™„ë£Œ: {elapsed:.3f}ì´ˆ ({len(chunks)}ê°œ ì²­í¬)")
        except Exception as e:
            print(f"      âŒ ì‹¤íŒ¨: {str(e)}")
            pipeline_times["ì²­í‚¹"] = 0
        
        # 3. ì„ë² ë”© ìƒì„±
        print("   3ë‹¨ê³„: ì„ë² ë”© ìƒì„±")
        start = time.time()
        try:
            chunk_texts = [chunk.content for chunk in chunks]
            embeddings = await asyncio.to_thread(self.generator.embed, chunk_texts)
            elapsed = time.time() - start
            pipeline_times["ì„ë² ë”© ìƒì„±"] = elapsed
            print(f"      ì™„ë£Œ: {elapsed:.3f}ì´ˆ ({len(embeddings)}ê°œ ì„ë² ë”©)")
        except Exception as e:
            print(f"      âŒ ì‹¤íŒ¨: {str(e)}")
            pipeline_times["ì„ë² ë”© ìƒì„±"] = 0
        
        # 4. Dual RAG ê²€ìƒ‰
        print("   4ë‹¨ê³„: Dual RAG ê²€ìƒ‰")
        start = time.time()
        try:
            query = self.legal_service._build_query_from_contract(test_text, None)
            query_embedding = await self.legal_service._get_embedding(query)
            
            legal_chunks = await self.legal_service._search_legal_chunks(query=query, top_k=8)
            elapsed = time.time() - start
            pipeline_times["RAG ê²€ìƒ‰"] = elapsed
            print(f"      ì™„ë£Œ: {elapsed:.3f}ì´ˆ (ë²•ë ¹ ì²­í¬: {len(legal_chunks)}ê°œ)")
        except Exception as e:
            print(f"      âŒ ì‹¤íŒ¨: {str(e)}")
            pipeline_times["RAG ê²€ìƒ‰"] = 0
        
        # 5. LLM ë¶„ì„
        print("   5ë‹¨ê³„: LLM ë¶„ì„")
        start = time.time()
        try:
            # ì²­í¬ì—ì„œ ê°„ë‹¨í•œ clauses ìƒì„± (ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš©)
            clauses = []
            for idx, chunk in enumerate(chunks[:4], 1):  # ìµœëŒ€ 4ê°œë§Œ
                clauses.append({
                    "id": f"clause-{idx}",
                    "title": f"ì œ{idx}ì¡°",
                    "content": chunk.content[:300]  # ì²˜ìŒ 300ìë§Œ
                })
            
            result = await self.legal_service._llm_summarize_risk(
                query=query,
                contract_text=test_text,
                contract_chunks=[],
                grounding_chunks=legal_chunks[:5],  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
                clauses=clauses  # clauses ì¶”ê°€
            )
            elapsed = time.time() - start
            pipeline_times["LLM ë¶„ì„"] = elapsed
            print(f"      ì™„ë£Œ: {elapsed:.3f}ì´ˆ (ì´ìŠˆ: {len(result.issues)}ê°œ)")
        except Exception as e:
            print(f"      âŒ ì‹¤íŒ¨: {str(e)}")
            pipeline_times["LLM ë¶„ì„"] = 0
        
        # ì „ì²´ ì‹œê°„
        total_time = sum(pipeline_times.values())
        pipeline_times["ì „ì²´"] = total_time
        print(f"\n   ì´ ì†Œìš” ì‹œê°„: {total_time:.3f}ì´ˆ")
        
        return pipeline_times
    
    async def test_situation_analysis_pipeline(self, iterations: int = 3) -> Dict[str, Any]:
        """ìƒí™©ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì „ì²´ í…ŒìŠ¤íŠ¸"""
        self.print_header("8. ìƒí™©ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥")
        
        if not SITUATION_WORKFLOW_AVAILABLE:
            print("   âš ï¸ LangGraphê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ìƒí™©ë¶„ì„ ì›Œí¬í”Œë¡œìš°ë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   í•´ê²°: pip install langgraph")
            return {}
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
        test_cases = [
            {
                "situation_text": "3ê°œì›”ì§¸ ì›”ê¸‰ì´ ëŠ¦ê²Œ ë“¤ì–´ì™€ìš”. ë§¤ë²ˆ ë‹¤ìŒ ë‹¬ ì¤‘ìˆœì— ë“¤ì–´ì˜¤ëŠ”ë°, ì´ë²ˆ ë‹¬ì€ ì•„ì§ë„ ì•ˆ ë“¤ì–´ì™”ì–´ìš”.",
                "category_hint": "unpaid_wage",
                "employment_type": "regular",
                "work_period": "1_3_years",
                "weekly_hours": 40,
                "is_probation": False,
                "social_insurance": "all",
            },
            {
                "situation_text": "ìˆ˜ìŠµ ê¸°ê°„ ì¤‘ì¸ë° ê°‘ìê¸° í•´ê³  í†µë³´ë¥¼ ë°›ì•˜ì–´ìš”. ì´ìœ ë¥¼ ë¬¼ì–´ë´ë„ ëª…í™•í•œ ë‹µë³€ì„ ì£¼ì§€ ì•Šì•„ìš”.",
                "category_hint": "unfair_dismissal",
                "employment_type": "regular",
                "work_period": "under_1_month",
                "weekly_hours": 40,
                "is_probation": True,
                "social_insurance": "all",
            },
            {
                "situation_text": "ì£¼ 60ì‹œê°„ì”© ì¼í•˜ëŠ”ë° ì—°ì¥ìˆ˜ë‹¹ì„ ì œëŒ€ë¡œ ë°›ì§€ ëª»í•˜ê³  ìˆì–´ìš”.",
                "category_hint": "overtime",
                "employment_type": "regular",
                "work_period": "1_3_years",
                "weekly_hours": 60,
                "is_probation": False,
                "social_insurance": "all",
            },
        ]
        
        all_pipeline_times = []
        
        for i in range(min(iterations, len(test_cases))):
            test_case = test_cases[i]
            print(f"\n   í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1}/{iterations}: {test_case['category_hint']}")
            print(f"   ìƒí™©: {test_case['situation_text'][:50]}...")
            
            pipeline_times = {}
            
            try:
                workflow = SituationWorkflow()
                
                # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„ ì¸¡ì •
                start = time.time()
                result = await workflow.run(test_case)
                total_time = time.time() - start
                pipeline_times["ì „ì²´ íŒŒì´í”„ë¼ì¸"] = total_time
                
                # ê²°ê³¼ í™•ì¸
                if result:
                    print(f"      âœ… ì™„ë£Œ: {total_time:.3f}ì´ˆ")
                    if "final_output" in result:
                        final = result["final_output"]
                        print(f"         - ìœ„í—˜ë„: {final.get('risk_score', 'N/A')}")
                        print(f"         - íŒë‹¨ ê¸°ì¤€: {len(final.get('criteria', []))}ê°œ")
                        print(f"         - í–‰ë™ ê³„íš: {len(final.get('action_plan', {}).get('steps', []))}ë‹¨ê³„")
                    else:
                        print(f"         - ë¶„ë¥˜: {result.get('classification', {}).get('classified_type', 'N/A')}")
                        print(f"         - ìœ„í—˜ë„: {result.get('classification', {}).get('risk_score', 'N/A')}")
                else:
                    print(f"      âš ï¸ ê²°ê³¼ ì—†ìŒ: {total_time:.3f}ì´ˆ")
                
                all_pipeline_times.append(pipeline_times)
                
            except Exception as e:
                print(f"      âŒ ì‹¤íŒ¨: {str(e)}")
                import traceback
                traceback.print_exc()
        
        # í†µê³„ ê³„ì‚°
        if all_pipeline_times:
            total_times = [pt["ì „ì²´ íŒŒì´í”„ë¼ì¸"] for pt in all_pipeline_times if "ì „ì²´ íŒŒì´í”„ë¼ì¸" in pt]
            if total_times:
                avg_time = statistics.mean(total_times)
                min_time = min(total_times)
                max_time = max(total_times)
                print(f"\n   í†µê³„:")
                print(f"      í‰ê· : {avg_time:.3f}ì´ˆ")
                print(f"      ìµœì†Œ: {min_time:.3f}ì´ˆ")
                print(f"      ìµœëŒ€: {max_time:.3f}ì´ˆ")
                
                return {
                    "í‰ê·  ì‹œê°„": avg_time,
                    "ìµœì†Œ ì‹œê°„": min_time,
                    "ìµœëŒ€ ì‹œê°„": max_time,
                    "í…ŒìŠ¤íŠ¸ íšŸìˆ˜": len(total_times),
                }
        
        return {}
    
    async def test_async_parallelism(self) -> Dict[str, float]:
        """ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼ í…ŒìŠ¤íŠ¸"""
        self.print_header("9. ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼")
        
        queries = [
            "ìˆ˜ìŠµ ê¸°ê°„ í•´ê³  ì¡°ê±´",
            "ì„ê¸ˆ ì§€ê¸‰ ì‹œê¸°",
            "ê·¼ë¡œì‹œê°„ ì œí•œ",
        ]
        
        # ìˆœì°¨ ì‹¤í–‰
        print("\n   ìˆœì°¨ ì‹¤í–‰:")
        start = time.time()
        for query in queries:
            try:
                await self.legal_service._search_legal_chunks(query=query, top_k=5)
            except Exception as e:
                print(f"      âŒ ì‹¤íŒ¨: {str(e)}")
        sequential_time = time.time() - start
        print(f"      ì™„ë£Œ: {sequential_time:.3f}ì´ˆ")
        
        # ë³‘ë ¬ ì‹¤í–‰
        print("\n   ë³‘ë ¬ ì‹¤í–‰:")
        start = time.time()
        try:
            tasks = [
                self.legal_service._search_legal_chunks(query=query, top_k=5)
                for query in queries
            ]
            await asyncio.gather(*tasks)
        except Exception as e:
            print(f"      âŒ ì‹¤íŒ¨: {str(e)}")
        parallel_time = time.time() - start
        print(f"      ì™„ë£Œ: {parallel_time:.3f}ì´ˆ")
        
        speedup = sequential_time / parallel_time if parallel_time > 0 else 0
        print(f"\n   ì†ë„ í–¥ìƒ: {speedup:.2f}ë°°")
        
        return {
            "ìˆœì°¨ ì‹¤í–‰": sequential_time,
            "ë³‘ë ¬ ì‹¤í–‰": parallel_time,
            "ì†ë„ í–¥ìƒ": speedup
        }
    
    def _save_result(self, test_name: str, times: List[float]):
        """ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥"""
        if not times:
            return
        
        avg = statistics.mean(times)
        median = statistics.median(times)
        min_time = min(times)
        max_time = max(times)
        std_dev = statistics.stdev(times) if len(times) > 1 else 0
        
        result_data = {
            "test_name": test_name,
            "statistics": {
                "mean": round(avg, 3),
                "median": round(median, 3),
                "min": round(min_time, 3),
                "max": round(max_time, 3),
                "std_dev": round(std_dev, 3),
                "count": len(times)
            },
            "raw_times": [round(t, 3) for t in times]
        }
        
        # ì „ì²´ ê²°ê³¼ì— ì¶”ê°€
        self.all_results["results"][test_name] = result_data
        
        # ì¦‰ì‹œ íŒŒì¼ì— ì €ì¥ (ì£¼ê¸°ì  ì €ì¥)
        try:
            with open(self.result_file, 'w', encoding='utf-8') as f:
                json.dump(self.all_results, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"   [ê²½ê³ ] ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _save_final_results(self):
        """ìµœì¢… ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥"""
        try:
            # ì „ì²´ ê²°ê³¼ ìš”ì•½ ì¶”ê°€
            summary = {}
            for test_name, times in self.results.items():
                if times:
                    summary[test_name] = {
                        "mean": round(statistics.mean(times), 3),
                        "count": len(times)
                    }
            
            self.all_results["summary"] = summary
            self.all_results["total_tests"] = len(self.results)
            
            # ìµœì¢… ì €ì¥
            with open(self.result_file, 'w', encoding='utf-8') as f:
                json.dump(self.all_results, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.result_file}")
        except Exception as e:
            print(f"\nâŒ ìµœì¢… ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def print_summary(self):
        """ì „ì²´ ê²°ê³¼ ìš”ì•½"""
        self.print_header("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        
        print("\nğŸ“ˆ ì£¼ìš” ì§€í‘œ:")
        for test_name, times in self.results.items():
            if times:
                avg = statistics.mean(times)
                print(f"   {test_name}: í‰ê·  {avg:.3f}ì´ˆ")
        
        print("\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
        if "ë‹¨ì¼ ì„ë² ë”©" in self.results and "ë°°ì¹˜ ì„ë² ë”©" in self.results:
            single_avg = statistics.mean(self.results.get("ë‹¨ì¼ ì„ë² ë”©", [0]))
            print(f"   - ë°°ì¹˜ ì„ë² ë”© ì‚¬ìš© ì‹œ ì†ë„ í–¥ìƒ ê°€ëŠ¥")
        
        if "ìºì‹œ ì—†ìŒ" in self.results and "ìºì‹œ ìˆìŒ" in self.results:
            no_cache = statistics.mean(self.results.get("ìºì‹œ ì—†ìŒ", [0]))
            with_cache = statistics.mean(self.results.get("ìºì‹œ ìˆìŒ", [0]))
            if no_cache > 0:
                cache_speedup = no_cache / with_cache if with_cache > 0 else 0
                print(f"   - ìºì‹œ ì‚¬ìš© ì‹œ {cache_speedup:.2f}ë°° ì†ë„ í–¥ìƒ")
        
        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        if self.save_results:
            self._save_final_results()


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"   ì„ë² ë”© ëª¨ë¸: {settings.local_embedding_model}")
    print(f"   LLM ëª¨ë¸: {settings.ollama_model}")
    print(f"   ë²¡í„° DB: {'Supabase' if settings.supabase_url else 'ChromaDB'}")
    
    tester = PerformanceTester()
    
    try:
        # 1. ë‹¨ì¼ ì„ë² ë”© ìƒì„±
        single_times = await tester.test_embedding_single(iterations=10)
        tester.print_result("ë‹¨ì¼ ì„ë² ë”© ìƒì„±", single_times)
        
        # 2. ë°°ì¹˜ ì„ë² ë”© ìƒì„±
        batch_results = await tester.test_embedding_batch(batch_sizes=[1, 5, 10, 20])
        for batch_size, times in batch_results.items():
            tester.print_result(f"ë°°ì¹˜ ì„ë² ë”© ({batch_size}ê°œ)", times)
        
        # 3. ìºì‹œ íš¨ê³¼
        cache_results = await tester.test_embedding_cache(iterations=20)
        for cache_type, times in cache_results.items():
            tester.print_result(f"ì„ë² ë”© ìƒì„± ({cache_type})", times)
        
        # 4. ë²¡í„° ê²€ìƒ‰
        search_times = await tester.test_vector_search(iterations=10)
        tester.print_result("ë²¡í„° ê²€ìƒ‰", search_times)
        
        # 5. LLM ì‘ë‹µ ìƒì„±
        llm_times = await tester.test_llm_response(iterations=5)
        tester.print_result("LLM ì‘ë‹µ ìƒì„±", llm_times)
        
        # 6. Dual RAG ê²€ìƒ‰
        dual_rag_times = await tester.test_dual_rag_search(iterations=5)
        tester.print_result("Dual RAG ê²€ìƒ‰", dual_rag_times)
        
        # 7. ì „ì²´ ê³„ì•½ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸
        pipeline_results = await tester.test_contract_analysis_pipeline()
        for stage, time_taken in pipeline_results.items():
            print(f"\n   {stage}: {time_taken:.3f}ì´ˆ")
        
        # íŒŒì´í”„ë¼ì¸ ê²°ê³¼ë„ ì €ì¥
        if pipeline_results:
            tester.all_results["pipeline_results"] = {
                stage: round(time_taken, 3) 
                for stage, time_taken in pipeline_results.items()
            }
            tester._save_final_results()
        
        # 8. ìƒí™©ë¶„ì„ íŒŒì´í”„ë¼ì¸
        situation_results = await tester.test_situation_analysis_pipeline(iterations=3)
        if situation_results:
            print(f"\n   ìƒí™©ë¶„ì„ íŒŒì´í”„ë¼ì¸ ê²°ê³¼:")
            for key, value in situation_results.items():
                if isinstance(value, float):
                    print(f"      {key}: {value:.3f}ì´ˆ")
                else:
                    print(f"      {key}: {value}")
            
            # ìƒí™©ë¶„ì„ ê²°ê³¼ë„ ì €ì¥
            tester.all_results["situation_pipeline_results"] = {
                key: round(value, 3) if isinstance(value, float) else value
                for key, value in situation_results.items()
            }
            tester._save_final_results()
        
        # 9. ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬
        async_results = await tester.test_async_parallelism()
        for test_type, time_taken in async_results.items():
            if isinstance(time_taken, float):
                print(f"\n   {test_type}: {time_taken:.3f}ì´ˆ")
            else:
                print(f"\n   {test_type}: {time_taken:.2f}ë°°")
        
        # ë¹„ë™ê¸° ê²°ê³¼ë„ ì €ì¥
        if async_results:
            tester.all_results["async_results"] = {
                test_type: round(time_taken, 3) if isinstance(time_taken, float) else round(time_taken, 2)
                for test_type, time_taken in async_results.items()
            }
            tester._save_final_results()
        
        # ìš”ì•½
        tester.print_summary()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())

