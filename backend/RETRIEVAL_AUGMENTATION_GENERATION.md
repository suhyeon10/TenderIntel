# ë°±ì—”ë“œ Retrieval-Augmentation-Generation ë‹¨ê³„ë³„ ìƒì„¸ ì„¤ëª…

## ğŸ“‹ ëª©ì°¨

1. [â‘¡ Retrieval ë‹¨ê³„ (VectorSearchTool)](#-retrieval-ë‹¨ê³„-vectorsearchtool)
2. [â‘¢ Augmentation ë‹¨ê³„](#-augmentation-ë‹¨ê³„)
3. [â‘£ Generation ë‹¨ê³„ (Explanation Tool)](#-generation-ë‹¨ê³„-explanation-tool)

---

## â‘¡ Retrieval ë‹¨ê³„ (VectorSearchTool)

### ê²€ìƒ‰ ëŒ€ìƒ ë°ì´í„°ì…‹ (Supabase + pgvector)

**êµ¬í˜„ ìœ„ì¹˜**: `backend/core/supabase_vector_store.py`

í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” **`legal_chunks`** í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ë©°, `source_type` í•„ë“œë¡œ ë¬¸ì„œ íƒ€ì…ì„ êµ¬ë¶„í•©ë‹ˆë‹¤:

| source_type | ì„¤ëª… | ì‹¤ì œ í…Œì´ë¸” |
|------------|------|------------|
| `law` | ë²•ë ¹ (ê·¼ë¡œê¸°ì¤€ë²•, ë…¸ë™ë²• ë“±) | `legal_chunks` |
| `manual` | ê°€ì´ë“œë¼ì¸/ë§¤ë‰´ì–¼ (ê³ ìš©ë…¸ë™ë¶€ ë§¤ë‰´ì–¼) | `legal_chunks` |
| `case` | ì¼€ì´ìŠ¤/ì‹œë‚˜ë¦¬ì˜¤ | `legal_chunks` |
| `standard_contract` | í‘œì¤€ ê³„ì•½ì„œ í…œí”Œë¦¿ | `legal_chunks` |

**ì°¸ê³ **: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ `law_chunks`, `standard_contract_chunks`, `guide_chunks`, `case_chunks`, `scenario_chunks`ëŠ” ëª¨ë‘ `legal_chunks` í…Œì´ë¸”ì˜ `source_type` í•„ë“œë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.

**ìŠ¤í‚¤ë§ˆ êµ¬ì¡°** (`backend/core/supabase_vector_store.py`):
```python
legal_chunks í…Œì´ë¸”:
- id: UUID (PK)
- external_id: TEXT (íŒŒì¼ëª…/ì¼€ì´ìŠ¤ ID)
- source_type: TEXT ('law' | 'manual' | 'case')
- title: TEXT (ë¬¸ì„œ ì œëª©)
- content: TEXT (ì²­í¬ í…ìŠ¤íŠ¸)
- chunk_index: INTEGER (ì²­í¬ ìˆœì„œ)
- file_path: TEXT (ì›ë³¸ íŒŒì¼ ê²½ë¡œ)
- metadata: JSONB (ì¶”ê°€ ë©”íƒ€ë°ì´í„°)
- embedding: VECTOR(384) (ì„ë² ë”© ë²¡í„°, bge-m3 ì‚¬ìš© ì‹œ)
- created_at: TIMESTAMPTZ
```

**ì½”ë“œ ìœ„ì¹˜**: 
- í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ: `supabase/migrations/002_legal_documents_schema.sql`
- ë²¡í„° ê²€ìƒ‰: `backend/core/supabase_vector_store.py::search_similar_legal_chunks()`

---

### ìµœì‹  êµ¬í˜„ì˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ

**êµ¬í˜„ ìœ„ì¹˜**: `backend/core/tools/vector_search_tool.py`

#### 1. ë²¡í„° ê²€ìƒ‰ (bge-m3 ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰)

**íš¨ê³¼**: í‘œí˜„ì´ ë‹¬ë¼ë„ ê°™ì€ ì˜ë¯¸ íƒì§€

```python
# backend/core/tools/vector_search_tool.py::_vector_search()
async def _vector_search(
    self,
    query_embedding: List[float],
    filters: Optional[Dict[str, Any]],
    top_k: int
) -> List[Dict[str, Any]]:
    """ë²¡í„° ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜)"""
    results = self.vector_store.search_similar_legal_chunks(
        query_embedding=query_embedding,
        top_k=top_k,
        filters=filters
    )
    return results
```

**íŠ¹ì§•**:
- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
- `bge-m3` ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (384ì°¨ì› ë˜ëŠ” 1024ì°¨ì›)
- `source_type` í•„í„°ë§ ì§€ì›

#### 2. í‚¤ì›Œë“œ ê²€ìƒ‰ (ë²•ë ¹ëª…, ì¡°í•­ ë²ˆí˜¸ ê¸°ë°˜ ì •ë°€ ê²€ìƒ‰)

**íš¨ê³¼**: ë²•ë ¹ ì¬í˜„ìœ¨ ê·¹ëŒ€í™”

```python
# backend/core/tools/vector_search_tool.py::_keyword_search()
async def _keyword_search(
    self,
    query: str,
    filters: Optional[Dict[str, Any]],
    top_k: int
) -> List[Dict[str, Any]]:
    """í‚¤ì›Œë“œ ê²€ìƒ‰ (ê°„ë‹¨í•œ êµ¬í˜„)"""
    # ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = re.findall(r'\w+', query.lower())
    
    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    # í‚¤ì›Œë“œ ë§¤ì¹­ ê°œìˆ˜ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
    keyword_score = keyword_matches / len(keywords) if keywords else 0
```

**íŠ¹ì§•**:
- ë²•ë ¹ëª…, ì¡°í•­ ë²ˆí˜¸ ë“± ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
- ì œëª©ê³¼ ë³¸ë¬¸ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰

#### 3. Hybrid Search (ë²¡í„° + í‚¤ì›Œë“œ ì¡°í•©)

**ê°€ì¤‘ì¹˜ ì¡°í•©**:
- ë²¡í„° ê²€ìƒ‰: 0.7
- í‚¤ì›Œë“œ ê²€ìƒ‰: 0.3

```python
# backend/core/tools/vector_search_tool.py::_hybrid_search()
async def _hybrid_search(
    self,
    query: str,
    query_embedding: List[float],
    filters: Optional[Dict[str, Any]],
    top_k: int
) -> List[Dict[str, Any]]:
    """Hybrid Search (í‚¤ì›Œë“œ + ë²¡í„°)"""
    # 1. ë²¡í„° ê²€ìƒ‰
    vector_results = await self._vector_search(...)
    
    # 2. í‚¤ì›Œë“œ ê²€ìƒ‰
    keyword_results = await self._keyword_search(...)
    
    # 3. ê²°ê³¼ ë³‘í•© ë° ê°€ì¤‘ì¹˜ ì ìš©
    combined = self._merge_results(
        vector_results=vector_results,
        keyword_results=keyword_results,
        vector_weight=0.7,
        keyword_weight=0.3
    )
```

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/vector_search_tool.py::_merge_results()`

#### 4. ìµœì‹ ì„± í•„í„° (updated_at ê¸°ë°˜ ìµœì‹  ë²•ë ¹ ìš°ì„ )

**íš¨ê³¼**: ê°œì • ë²•ë ¹ ë°˜ì˜ ì •í™•ë„ í–¥ìƒ

**ì°¸ê³ **: í˜„ì¬ êµ¬í˜„ì—ì„œëŠ” `created_at` í•„ë“œë¥¼ ì‚¬ìš©í•˜ë©°, í–¥í›„ `updated_at` í•„ë“œ ì¶”ê°€ ì˜ˆì •ì…ë‹ˆë‹¤.

**ì½”ë“œ ìœ„ì¹˜**: `backend/CONTRACT_ANALYSIS_TOOLS_DESIGN.md` (ì„¤ê³„ ë¬¸ì„œì— ëª…ì‹œ)

#### 5. MMR ì¬ë­í‚¹ (ë‹¤ì–‘ì„± + ìœ ì‚¬ë„ ê· í˜•)

**íš¨ê³¼**: ì¤‘ë³µ ì œê±°, í•µì‹¬ ê·¼ê±° ìš°ì„ 

```python
# backend/core/tools/vector_search_tool.py::_mmr_rerank()
def _mmr_rerank(
    self,
    query_embedding: List[float],
    results: List[Dict[str, Any]],
    top_k: int,
    diversity: float = 0.5
) -> List[Dict[str, Any]]:
    """
    MMR (Maximum Marginal Relevance) ì¬ë­í‚¹
    
    ë‹¤ì–‘ì„±ê³¼ ê´€ë ¨ì„±ì„ ê· í˜•ìˆê²Œ ê³ ë ¤í•˜ì—¬ ì¬ë­í‚¹
    - diversity: ë‹¤ì–‘ì„± íŒŒë¼ë¯¸í„° (0-1, ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘)
    """
    # MMR ì ìˆ˜ = Î» * relevance - (1 - Î») * max_similarity
    mmr_score = diversity * relevance - (1 - diversity) * min_similarity
```

**íŠ¹ì§•**:
- ìœ ì‚¬ë„ì™€ ë‹¤ì–‘ì„±ì˜ ê· í˜•
- ì¤‘ë³µëœ ì¡°ë¬¸ ì œê±°
- ë‹¤ì–‘í•œ ê´€ì ì˜ ë²•ë ¹ ì œê³µ

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/vector_search_tool.py::_mmr_rerank()`

**ì°¸ê³  ë¬¸ì„œ**: `HALLUCINATION_REDUCTION.md`

---

### ê²€ìƒ‰ ê²°ê³¼ì˜ ë©”íƒ€ë°ì´í„°

**êµ¬í˜„ ìœ„ì¹˜**: `backend/core/tools/vector_search_tool.py::SearchResult`

```python
@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼"""
    id: str
    external_id: str
    source_type: str  # "law", "standard_contract", "manual", "case"
    title: str
    content: str
    chunk_index: int
    file_path: Optional[str]
    metadata: Dict[str, Any]
    score: float  # ìœ ì‚¬ë„ ì ìˆ˜ (0-1)
    search_type: str  # "vector" | "hybrid" | "mmr"
```

**ë©”íƒ€ë°ì´í„° í•„ë“œ**:
- `source_type`: ë¬¸ì„œ íƒ€ì… (law/standard_contract/manual/case)
- `article_number`: ì¡°í•­ ë²ˆí˜¸ (metadata JSONBì— ì €ì¥)
- `updated_at`: ìµœì‹ ì„± ì •ë³´ (í–¥í›„ ì¶”ê°€ ì˜ˆì •)
- `similarity_score`: ìœ ì‚¬ë„ ì ìˆ˜ (0-1)

**â†’ LLMì´ ëª…í™•íˆ ì¶œì²˜ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ì„¤ê³„**

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/vector_search_tool.py::execute()`

---

## â‘¢ Augmentation ë‹¨ê³„ (LLM ì…ë ¥ ì „ ì¦ê°•)

**êµ¬í˜„ ìœ„ì¹˜**: `backend/core/prompts.py`, `backend/core/legal_rag_service.py`

### ì¦ê°• ì›ì¹™

#### 1. ê·¼ê±° ì—†ëŠ” ìƒì„± ê¸ˆì§€

**êµ¬í˜„**: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì—ì„œ ê²€ìƒ‰ëœ ë²•ë ¹ë§Œ ì°¸ì¡°í•˜ë„ë¡ ì œí•œ

```python
# backend/core/prompts.py::build_legal_chat_prompt()
# ë²•ë ¹ ì²­í¬ ì¶”ê°€
if legal_chunks:
    context_parts.append("\n=== ê´€ë ¨ ë²•ë ¹/ê°€ì´ë“œë¼ì¸ ===")
    for chunk in legal_chunks[:5]:  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
        source_type = getattr(chunk, 'source_type', 'law')
        title = getattr(chunk, 'title', '')
        snippet = getattr(chunk, 'snippet', getattr(chunk, 'content', ''))[:500]
        context_parts.append(f"[{source_type}] {title}\n{snippet}")
```

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/prompts.py::build_legal_chat_prompt()`

#### 2. ê°•ì œ ì¡°ë¬¸ ë²ˆí˜¸ + ì›ë¬¸ ì‚½ì…

**ì˜ˆì‹œ**: `[ê·¼ë¡œê¸°ì¤€ë²• ì œ26ì¡°] í•´ê³ ì˜ ì˜ˆê³ : "ì‚¬ìš©ìëŠ” ê·¼ë¡œìë¥¼ í•´ê³ í•˜ë ¤ë©´â€¦"`

**êµ¬í˜„**: `backend/core/tools/llm_explanation_tool.py::_extract_legal_basis()`

```python
def _extract_legal_basis(
    self,
    legal_contexts: List[Dict[str, Any]],
    provision: Dict[str, Any]
) -> List[str]:
    """ë²•ë ¹ ì¡°ë¬¸ ìë™ ì¶”ì¶œ"""
    legal_basis = []
    
    for ctx in legal_contexts[:5]:  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
        source_type = ctx.get("source_type", "")
        title = ctx.get("title", "")
        content = ctx.get("content", "")
        
        # ë²•ë ¹ ì¡°ë¬¸ íŒ¨í„´ ì¶”ì¶œ (ì œnì¡°, ì œní•­ ë“±)
        article_pattern = re.compile(r'ì œ\s*\d+\s*ì¡°[^\n]*', re.MULTILINE)
        articles = article_pattern.findall(content)
        
        if articles:
            # ë²•ë ¹ëª…ê³¼ ì¡°ë¬¸ ê²°í•©
            for article in articles[:2]:  # ìµœëŒ€ 2ê°œ
                legal_basis.append(f"{title} {article.strip()}")
```

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/llm_explanation_tool.py::_extract_legal_basis()`

#### 3. êµ¬ë²„ì „/ì¶©ëŒ ê·¼ê±° ì œê±°

**êµ¬í˜„**: ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¤‘ë³µ ì œê±° ë° ìµœì‹ ì„± í•„í„°ë§ (í–¥í›„ `updated_at` í•„ë“œ í™œìš©)

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/vector_search_tool.py::_mmr_rerank()`

#### 4. ì•ˆì „ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©

**êµ¬í˜„**: `backend/core/prompts.py::LEGAL_CHAT_SYSTEM_PROMPT`

```python
LEGAL_CHAT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ ë…¸ë™ë²•/ê³„ì•½ ì‹¤ë¬´ì— íŠ¹í™”ëœ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì¤‘ìš”í•œ ì›ì¹™:**
1. ì´ ì„œë¹„ìŠ¤ëŠ” ë²•ë¥  ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤. ì •ë³´ ì•ˆë‚´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
2. í•­ìƒ ê´€ë ¨ ë²•ë ¹/ê°€ì´ë“œë¥¼ ê·¼ê±°ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
3. ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ì œëª©, ë¦¬ìŠ¤íŠ¸, ê°•ì¡° ë“±).
4. ë‹µë³€ ë§ˆì§€ë§‰ì— "ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥" ë¬¸êµ¬ë¥¼ í¬í•¨í•˜ì„¸ìš”.

**ë‹µë³€ êµ¬ì¡°:**
1. ìš”ì•½ ê²°ë¡  (í•œ ë¬¸ì¥)
2. ì™œ ìœ„í—˜í•œì§€ (ë²•ì  ë¦¬ìŠ¤í¬)
3. ì‹¤ë¬´ í˜‘ìƒ í¬ì¸íŠ¸ (í˜„ì‹¤ì ì¸ ì˜µì…˜)
4. ì°¸ê³  ë²•ë ¹/í‘œì¤€ ê³„ì•½ ìš”ì•½
"""
```

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/prompts.py::LEGAL_CHAT_SYSTEM_PROMPT`

#### 5. ë°ì´í„° ë¶€ì¡± ì‹œ ìë™ ì „í™˜

**êµ¬í˜„**: ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ ìƒì„±

```python
# backend/core/tools/llm_explanation_tool.py::_generate_default_explanation()
def _generate_default_explanation(
    self,
    provision: Dict[str, Any],
    risk_score: float,
    issue_type: str,
    legal_contexts: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """LLM ë¹„í™œì„±í™” ì‹œ ê¸°ë³¸ ì„¤ëª… ìƒì„±"""
    # ê¸°ë³¸ ì„¤ëª… ìƒì„±
    # ë²•ë ¹ ì¡°ë¬¸ ì¶”ì¶œ
    legal_basis = self._extract_legal_basis(legal_contexts, provision)
    
    # ê¸°ë³¸ ìˆ˜ì • ì œì•ˆ
    suggested_revision = f"í‘œì¤€ ê³„ì•½ì„œ í˜•ì‹ì— ë§ê²Œ '{prov_title}' ì¡°í•­ì„ ìˆ˜ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
```

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/llm_explanation_tool.py::_generate_default_explanation()`

**ì°¸ê³  ë¬¸ì„œ**: `HALLUCINATION_REDUCTION.md` (ì¶œë ¥ ì œì•½ ì„¹ì…˜)

---

## â‘£ Generation ë‹¨ê³„ (Explanation Tool)

**êµ¬í˜„ ìœ„ì¹˜**: `backend/core/tools/llm_explanation_tool.py`

### ìµœì¢…ì ìœ¼ë¡œ ì œê³µë˜ëŠ” ì •ë³´

#### 1. ê³„ì•½ì„œ ìœ„í—˜ë„ ì ìˆ˜ (0â€“100)

**êµ¬í˜„**: `backend/core/tools/risk_scoring_tool.py`

```python
{
    "overall_risk_score": float,  # ì „ì²´ ìœ„í—˜ë„ (0-100)
    "risk_level": str,  # "low" | "medium" | "high"
    "risk_breakdown": {
        "working_hours": float,  # ê·¼ë¡œì‹œê°„ ê´€ë ¨ ìœ„í—˜ë„
        "wage": float,  # ì„ê¸ˆ ê´€ë ¨ ìœ„í—˜ë„
        "probation_termination": float,  # ìˆ˜ìŠµ/í•´ê³  ê´€ë ¨ ìœ„í—˜ë„
        "stock_option_ip": float  # ìŠ¤í†¡ì˜µì…˜/IP ê´€ë ¨ ìœ„í—˜ë„
    }
}
```

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/risk_scoring_tool.py::execute()`

#### 2. ì˜ì—­ë³„ ìœ„í—˜ë„

**ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ì¹˜**:
- `working_hours` (ê·¼ë¡œì‹œê°„/íœ´ê²Œ): 0.25
- `wage` (ë³´ìˆ˜/ìˆ˜ë‹¹): 0.30
- `probation_termination` (ìˆ˜ìŠµ/í•´ê³ ): 0.25
- `stock_option_ip` (ìŠ¤í†¡ì˜µì…˜/IP): 0.20

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/risk_scoring_tool.py::_calculate_risk_breakdown()`

**ì°¸ê³  ë¬¸ì„œ**: `HALLUCINATION_REDUCTION.md` (ë¦¬ìŠ¤í¬ ìŠ¤ì½”ì–´ ê³„ì‚° ë°©ì‹)

#### 3. ìœ„í—˜ ì¡°í•­ ë¶„ì„

**êµ¬í˜„**: `backend/core/tools/llm_explanation_tool.py::execute()`

**ì œê³µ ì •ë³´**:
- **"ì™œ ìœ„í—˜í•œì§€?"**: `explanation` í•„ë“œ
- **"ì–´ë–¤ ë²•ë ¹ê³¼ ì¶©ëŒí•˜ëŠ”ì§€?"**: `legal_basis` í•„ë“œ
- **"í‘œì¤€ê³„ì•½ê³¼ ë¹„êµí•´ ë¬´ì—‡ì´ ë‹¤ë¥¸ì§€?"**: í”„ë¡¬í”„íŠ¸ì— í¬í•¨

```python
@dataclass
class ExplanationResult:
    """ì„¤ëª… ê²°ê³¼"""
    explanation: str  # ìœ„í—˜ ì‚¬ìœ  ì„¤ëª…
    legal_basis: List[str]  # ê´€ë ¨ ë²•ë ¹ ì¡°ë¬¸
    suggested_revision: str  # ìˆ˜ì • ì œì•ˆ ë¬¸êµ¬
    rationale: str  # ìˆ˜ì • ì´ìœ 
    suggested_questions: List[str]  # íšŒì‚¬ì— ì§ˆë¬¸í•  ë¬¸êµ¬
```

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/llm_explanation_tool.py::ExplanationResult`

#### 4. ê³„ì•½ì„œ ì›ë¬¸ í•˜ì´ë¼ì´íŠ¸ ì—°ë™

**êµ¬í˜„**: í”„ë¡ íŠ¸ì—”ë“œì—ì„œ `article_number`ì™€ `originalText`ë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´ë¼ì´íŠ¸

**ì½”ë“œ ìœ„ì¹˜**: 
- ë°±ì—”ë“œ: `backend/core/tools/llm_explanation_tool.py::execute()` (provision ì •ë³´ ë°˜í™˜)
- í”„ë¡ íŠ¸ì—”ë“œ: `src/app/legal/contract/[docId]/page.tsx`

#### 5. ë²•ë ¹ ê¸°ë°˜ ìˆ˜ì • ì œì•ˆ ë¬¸êµ¬

**êµ¬í˜„**: `backend/core/tools/llm_explanation_tool.py::_generate_llm_explanation()`

```python
prompt = f"""...
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "explanation": "ì´ ì¡°í•­ì˜ ë¬¸ì œì ê³¼ ë²•ì  ìœ„í—˜ì„±ì„ ìƒì„¸íˆ ì„¤ëª… (200-300ì)",
    "legal_basis": ["ê·¼ë¡œê¸°ì¤€ë²• ì œ27ì¡°", "ê·¼ë¡œê¸°ì¤€ë²• ì œ56ì¡°"],
    "suggested_revision": "ìˆ˜ì • ì œì•ˆ ë¬¸êµ¬ (êµ¬ì²´ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±)",
    "rationale": "ì™œ ì´ë ‡ê²Œ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ì§€ ì´ìœ  (100-150ì)",
    "suggested_questions": [
        "íšŒì‚¬ì— ì´ë ‡ê²Œ ì§ˆë¬¸í•  ìˆ˜ ìˆëŠ” ë¬¸êµ¬ 1",
        "íšŒì‚¬ì— ì´ë ‡ê²Œ ì§ˆë¬¸í•  ìˆ˜ ìˆëŠ” ë¬¸êµ¬ 2",
        "íšŒì‚¬ì— ì´ë ‡ê²Œ ì§ˆë¬¸í•  ìˆ˜ ìˆëŠ” ë¬¸êµ¬ 3"
    ]
}}
"""
```

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/tools/llm_explanation_tool.py::_generate_llm_explanation()`

#### 6. ë‹¨ê³„ë³„ ëŒ€ì‘ ê°€ì´ë“œ

**ì œê³µ ì •ë³´**:
- **í•´ì•¼ í•  ì¼**: `suggested_revision` (ìˆ˜ì • ì œì•ˆ)
- **í•˜ì§€ ë§ì•„ì•¼ í•  ì¼**: `explanation` (ìœ„í—˜ì„± ì„¤ëª…)
- **ì‹ ê³  ê¸°ê´€ ì•ˆë‚´**: í”„ë¡¬í”„íŠ¸ì— í¬í•¨ (ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥)

**ì½”ë“œ ìœ„ì¹˜**: `backend/core/prompts.py::LEGAL_CHAT_SYSTEM_PROMPT`

---

## ğŸ“ ê´€ë ¨ íŒŒì¼ ìœ„ì¹˜ ìš”ì•½

### Retrieval ë‹¨ê³„
- **VectorSearchTool**: `backend/core/tools/vector_search_tool.py`
- **SupabaseVectorStore**: `backend/core/supabase_vector_store.py`
- **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ**: `HALLUCINATION_REDUCTION.md`

### Augmentation ë‹¨ê³„
- **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**: `backend/core/prompts.py`
- **ë²•ë ¹ ì¡°ë¬¸ ì¶”ì¶œ**: `backend/core/tools/llm_explanation_tool.py::_extract_legal_basis()`
- **RAG ì„œë¹„ìŠ¤**: `backend/core/legal_rag_service.py`

### Generation ë‹¨ê³„
- **Explanation Tool**: `backend/core/tools/llm_explanation_tool.py`
- **Risk Scoring Tool**: `backend/core/tools/risk_scoring_tool.py`
- **ë„êµ¬ ì„¤ê³„ ë¬¸ì„œ**: `backend/CONTRACT_ANALYSIS_TOOLS_DESIGN.md`

### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ
- **legal_chunks í…Œì´ë¸”**: `supabase/migrations/002_legal_documents_schema.sql`
- **ë°±ì—”ë“œ ë¡œì§ ì„¤ëª…**: `backend/BACKEND_LOGIC_EXPLANATION.md`

---

## ğŸ”— ì°¸ê³  ë¬¸ì„œ

- [HALLUCINATION_REDUCTION.md](./HALLUCINATION_REDUCTION.md) - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ ìƒì„¸
- [CONTRACT_ANALYSIS_TOOLS_DESIGN.md](./CONTRACT_ANALYSIS_TOOLS_DESIGN.md) - ë„êµ¬ ì„¤ê³„ ë¬¸ì„œ
- [BACKEND_LOGIC_EXPLANATION.md](./BACKEND_LOGIC_EXPLANATION.md) - ë°±ì—”ë“œ ë¡œì§ ìƒì„¸ ì„¤ëª…

